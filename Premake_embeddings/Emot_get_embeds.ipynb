{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880aaf68-fb7f-4f1e-9496-39e38f9b3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import torch\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaModel\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c95f2-a790-4845-9ba3-2c01c8969e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_train = pd.read_csv('train.tsv.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b118a-3133-4934-baac-aa3d9050cada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
       "      <td>18</td>\n",
       "      <td>edsb738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>6</td>\n",
       "      <td>ee7fdou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>3</td>\n",
       "      <td>efgbhks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>13</td>\n",
       "      <td>ed1naf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>17</td>\n",
       "      <td>eecwmbq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0   1        2\n",
       "0      My favourite food is anything I didn't have to...  27  eebbqej\n",
       "1      Now if he does off himself, everyone will thin...  27  ed00q6i\n",
       "2                         WHY THE FUCK IS BAYLESS ISOING   2  eezlygj\n",
       "3                            To make her feel threatened  14  ed7ypvh\n",
       "4                                 Dirty Southern Wankers   3  ed0bdzj\n",
       "...                                                  ...  ..      ...\n",
       "43405  Added you mate well I’ve just got the bow and ...  18  edsb738\n",
       "43406  Always thought that was funny but is it a refe...   6  ee7fdou\n",
       "43407  What are you talking about? Anything bad that ...   3  efgbhks\n",
       "43408            More like a baptism, with sexy results!  13  ed1naf8\n",
       "43409                                    Enjoy the ride!  17  eecwmbq\n",
       "\n",
       "[43410 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9df08-6af0-4f1c-96ff-756b966ab0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_test = pd.read_csv('test.tsv.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aeb0e7-c482-47a2-941f-cadec57d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_dev = pd.read_csv('dev.tsv.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90545f-fdf5-4d2f-8b20-422cbe2be627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255513f-ff6a-4abe-a0a3-c8cac3fc2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e695e3-dfe9-4c39-a6d0-50f3d3393ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r)\n",
    "print(a)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c16deb-dd6b-4c86-9aec-9a6d14699409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "R_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
    "Roberta_model = RobertaModel.from_pretrained(\"roberta-large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f1c8f-1e31-4b5d-b098-886e58753473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n",
    "# print(t/1000000000)\n",
    "# print(r/1000000000)\n",
    "# print(a/1000000000)\n",
    "# print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41175509-4ed3-45db-98e9-e89e532e5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion_train_roberta_embeddings = []\n",
    "# with torch.no_grad():\n",
    "#     for idx, val in enumerate(go_emotions_train.values):\n",
    "#         R_tokenized = R_tokenizer(val[0], return_tensors = 'pt', truncation=True).to(device)\n",
    "#         #print(R_tokenized.shape)\n",
    "#         R_embed = Roberta_model(**R_tokenized).last_hidden_state.squeeze()\n",
    "#         print(R_embed.shape)\n",
    "#         del R_tokenized\n",
    "#         R_embed_cpu = R_embed.to('cpu')\n",
    "#         del R_embed\n",
    "#         emotion_train_roberta_embeddings.append(R_embed_cpu)\n",
    "#         if idx%1000 == 0:\n",
    "#             t = torch.cuda.get_device_properties(0).total_memory\n",
    "#             r = torch.cuda.memory_reserved(0)\n",
    "#             a = torch.cuda.memory_allocated(0)\n",
    "#             f = r-a  # free inside reserved\n",
    "#             print(t/1000000000)\n",
    "#             print(r/1000000000)\n",
    "#             print(a/1000000000)\n",
    "#             print(f/1000000000)\n",
    "#             print(idx)\n",
    "#         break\n",
    "#         #print(val[0])\n",
    "#         #print(type(R_tokenized))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ecd95-7415-4af5-8933-6d41fe8ffb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "1.43654912\n",
      "1.421448192\n",
      "0.015100928\n",
      "0\n",
      "42.314694656\n",
      "1.43654912\n",
      "1.421448192\n",
      "0.015100928\n",
      "1000\n",
      "42.314694656\n",
      "1.43654912\n",
      "1.421448192\n",
      "0.015100928\n",
      "2000\n",
      "42.314694656\n",
      "1.43654912\n",
      "1.421448192\n",
      "0.015100928\n",
      "3000\n",
      "42.314694656\n",
      "1.438646272\n",
      "1.421448192\n",
      "0.01719808\n",
      "4000\n",
      "42.314694656\n",
      "1.438646272\n",
      "1.421448192\n",
      "0.01719808\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "emotion_dev_roberta_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for idx, val in enumerate(go_emotions_dev.values):\n",
    "        R_tokenized = R_tokenizer(val[0], return_tensors = 'pt', truncation=True).to(device)\n",
    "        #print(R_tokenized.shape)\n",
    "        R_embed = Roberta_model(**R_tokenized).last_hidden_state.squeeze()\n",
    "        #print(R_embed.shape)\n",
    "        del R_tokenized\n",
    "        R_embed_cpu = R_embed.to('cpu')\n",
    "        del R_embed\n",
    "        emotion_dev_roberta_embeddings.append(R_embed_cpu)\n",
    "        if idx%1000 == 0:\n",
    "            t = torch.cuda.get_device_properties(0).total_memory\n",
    "            r = torch.cuda.memory_reserved(0)\n",
    "            a = torch.cuda.memory_allocated(0)\n",
    "            f = r-a  # free inside reserved\n",
    "            print(t/1000000000)\n",
    "            print(r/1000000000)\n",
    "            print(a/1000000000)\n",
    "            print(f/1000000000)\n",
    "            print(idx)\n",
    "        #print(val[0])\n",
    "        #print(type(R_tokenized))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8bb5b-8f53-4731-9bd8-c82287b5bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(emotion_train_roberta_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d41240-c9b6-4b43-b62a-19088ba9aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_head_model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "gpt_head_transformer = gpt_head_model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537b5cb-01b5-44d2-a0d8-3b612b344512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "7.868514304\n",
      "7.84389376\n",
      "0.024620544\n",
      "0\n",
      "42.314694656\n",
      "7.90626304\n",
      "7.84389376\n",
      "0.06236928\n",
      "1000\n",
      "42.314694656\n",
      "7.90626304\n",
      "7.84389376\n",
      "0.06236928\n",
      "2000\n",
      "42.314694656\n",
      "7.90626304\n",
      "7.84389376\n",
      "0.06236928\n",
      "3000\n",
      "42.314694656\n",
      "7.9691776\n",
      "7.84389376\n",
      "0.12528384\n",
      "4000\n",
      "42.314694656\n",
      "7.99014912\n",
      "7.84389376\n",
      "0.14625536\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "emotion_dev_gpt_logits = []\n",
    "with torch.no_grad():\n",
    "    for idx, val in enumerate(go_emotions_dev.values):\n",
    "        gpt_tokenized = gpt_tokenizer(val[0], return_tensors = 'pt', truncation=True).to(device)\n",
    "        gpt_embed = gpt_head_transformer(**gpt_tokenized).last_hidden_state.squeeze()\n",
    "        del gpt_tokenized\n",
    "        gpt_embed_cpu = gpt_embed.to('cpu')\n",
    "        del gpt_embed\n",
    "        emotion_dev_gpt_logits.append(gpt_embed_cpu)\n",
    "        if idx%1000 == 0:\n",
    "            t = torch.cuda.get_device_properties(0).total_memory\n",
    "            r = torch.cuda.memory_reserved(0)\n",
    "            a = torch.cuda.memory_allocated(0)\n",
    "            f = r-a  # free inside reserved\n",
    "            print(t/1000000000)\n",
    "            print(r/1000000000)\n",
    "            print(a/1000000000)\n",
    "            print(f/1000000000)\n",
    "            print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22526fc2-19d9-430c-ac5f-e8ca155bad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(emotion_dev_roberta_embeddings, 'emo_roberta_dev.pt')\n",
    "torch.save(emotion_dev_gpt_logits, 'emo_gpt2_dev.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4bcd7-7fd6-469f-ac74-475cac868d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(emotion_train_gpt_logits))\n",
    "# print(len(emotion_train_roberta_embeddings))\n",
    "# print(emotion_train_gpt_logits[0].shape)\n",
    "# print(emotion_train_roberta_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e39461-6332-46d1-9edd-856bf007b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(emotion_train_gpt_logits, 'emo_gpt2-xl.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469aee8-61a2-492e-9c71-4296659d11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(emotion_train_roberta_embeddings, 'emo_Roberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b32613-365c-4883-9afd-7c4f274c8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n",
    "# print(t/1000000000)\n",
    "# print(r/1000000000)\n",
    "# print(a/1000000000)\n",
    "# print(f/1000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ea757-2176-4282-8f99-b4a7e7ac6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del gpt_head_model\n",
    "# del Roberta_model\n",
    "# del gpt_head_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405d901-5f95-4e5e-8ceb-fecf3d5825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3075084-371e-43e6-a04d-7ac57a825803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n",
    "# print(t/1000000000)\n",
    "# print(r/1000000000)\n",
    "# print(a/1000000000)\n",
    "# print(f/1000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3ffc1-7629-472f-894c-a2242297bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPTNeoModel, GPTNeoForCausalLM\n",
    "# gpt_neo_tokenizer =GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "# gpt_neo_head_transformer = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\").transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f0389-5c31-4ef0-b64d-258c2db14ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPTNeoModel, GPTNeoForCausalLM\n",
    "# gpt_neo_tokenizer =GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "# gpt_neo_head_transformer = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17cddd-8474-49ec-bf05-91d2e6cda0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del gpt_neo_head_model\n",
    "# del gpt_neo_head_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f531a5a-dd6a-49a5-8e6f-028d056b2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(emotion_train_neo_logits))\n",
    "# print(emotion_train_neo_logits[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd81dd7-0c7c-43a6-a8ed-d5eab345e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.cuda.get_device_properties(0).total_memory\n",
    "# r = torch.cuda.memory_reserved(0)\n",
    "# a = torch.cuda.memory_allocated(0)\n",
    "# f = r-a  # free inside reserved\n",
    "# print(t/1000000000)\n",
    "# print(r/1000000000)\n",
    "# print(a/1000000000)\n",
    "# print(f/1000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722abb38-0c8d-4bef-96e1-b62883009357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion_train_neo_logits = []\n",
    "# with torch.no_grad():\n",
    "#     for idx, val in enumerate(go_emotions_train.values):\n",
    "#         neo_tokenized = gpt_neo_tokenizer(val[0], return_tensors = 'pt', truncation=True).to(device)\n",
    "#         neo_embed = gpt_neo_head_transformer(**neo_tokenized).last_hidden_state.squeeze()\n",
    "#         del neo_tokenized\n",
    "#         neo_embed_cpu = neo_embed.to('cpu')\n",
    "#         del neo_embed\n",
    "#         emotion_train_neo_logits.append(neo_embed_cpu)\n",
    "#         if idx%1000 == 0:\n",
    "#             t = torch.cuda.get_device_properties(0).total_memory\n",
    "#             r = torch.cuda.memory_reserved(0)\n",
    "#             a = torch.cuda.memory_allocated(0)\n",
    "#             f = r-a  # free inside reserved\n",
    "#             print(t/1000000000)\n",
    "#             print(r/1000000000)\n",
    "#             print(a/1000000000)\n",
    "#             print(f/1000000000)\n",
    "#             print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067196a-7483-4f35-8573-158be3c50552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(emotion_train_neo_logits, 'emo_neo1_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60020536-af46-440f-9a56-3059ce7f7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
