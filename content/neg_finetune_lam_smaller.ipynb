{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56ca7c0-996c-42d6-b331-9994049ac0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.26.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.local/lib/python3.8/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.8/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08052d9-593b-4b2a-badd-e5ad9678eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, AutoConfig\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "from torch import optim\n",
    "import gc\n",
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8344b304-4ce7-4f78-a014-9568478977b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:7\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:1,3,5\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ab763e-7474-4e70-bc74-02ecd18f2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "base_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87421647-abe6-486a-8d6e-0558a2f72918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # head_model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "# head_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92019ff-6f5a-4f82-a763-b2c05142924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pos_path = \"/home/ubuntu/IMDB_train/pos/\"\n",
    "neg_path = \"/home/ubuntu/IMDB_train/neg/\"\n",
    "\n",
    "\n",
    "pos_token_list = []\n",
    "pos_text_list = []\n",
    "neg_token_list = []\n",
    "neg_text_list = []\n",
    "\n",
    "os.chdir(pos_path)\n",
    "  \n",
    "\n",
    "for file in os.listdir():\n",
    "    if not file.endswith('.txt'):\n",
    "        continue\n",
    "    with open(pos_path+file, 'r') as f:\n",
    "        pos_text = f.read()\n",
    "        # put into text list\n",
    "        pos_text_list.append(pos_text)\n",
    "        #tokenize and put into token list\n",
    "        #pos_token_list.append(base_tokenizer.encode(pos_text, return_tensors = 'pt'))\n",
    "\n",
    "os.chdir(neg_path)\n",
    "\n",
    "for file in os.listdir():\n",
    "    if not file.endswith('.txt'):\n",
    "        continue\n",
    "    with open(neg_path+file, 'r') as f:\n",
    "        neg_text = f.read()\n",
    "        # put into text list\n",
    "        neg_text_list.append(neg_text)\n",
    "        #tokenize and put into token list\n",
    "        #neg_token_list.append(base_tokenizer.encode(neg_text_list, return_tensors = 'pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a912b0-14a2-4087-9ad5-edc3df17122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "# ref https://stackoverflow.com/questions/753052/strip-html-from-strings-in-python\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "# cleaned = test_text_pos.replace('<br /><br />', ' ')\n",
    "# print(cleaned)\n",
    "\n",
    "def clean_imdb(review_list):\n",
    "    for review in range(len(review_list)):\n",
    "        cleaned_review = strip_tags(review_list[review])\n",
    "        review_list[review] = cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c68ab3-e82b-4bc3-bd9c-fb3c7cc1a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imdb(neg_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22aef918-a39a-47b1-8427-89376cd4ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text\n",
      "0      the tortuous emotional impact is degrading, wh...\n",
      "1      The Horror Channel plays nothing but erotic so...\n",
      "2      I saw this piece of garbage on AMC last night,...\n",
      "3      The film begins with promise, but lingers too ...\n",
      "4      the more i think about it, there was nothing r...\n",
      "...                                                  ...\n",
      "12495  There's a lot of good that can be said for thi...\n",
      "12496  Wow. Some movies just leave me speechless. Thi...\n",
      "12497  This is only a response to the yahoo who says ...\n",
      "12498  This film is about a family trying to come to ...\n",
      "12499  Kojak meets the mafia. Telly Savales is one of...\n",
      "\n",
      "[12500 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# df_pos_tokens = pd.DataFrame(pos_token_list, columns = ['tokens'])\n",
    "# print(df_pos_tokens)\n",
    "df_neg_text = pd.DataFrame(neg_text_list, columns = ['text'])\n",
    "print(df_neg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00e1d3d-cffe-4669-a617-1c1b91acd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I work as a data scientist\"\n",
    "# text_ids = base_tokenizer.encode(text, return_tensors = 'pt')\n",
    "# print(text_ids.shape)\n",
    "# print(head_model(text_ids.to(device)).logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6e0d99-dae4-4878-ab93-d87d79d746d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbNeg(Dataset):  \n",
    "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "        self.tokenizer = base_tokenizer # can change\n",
    "        self.text = []\n",
    "\n",
    "        for row in df_neg_text['text']:\n",
    "            self.text.append(torch.tensor(\n",
    "                self.tokenizer.encode((f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\"))\n",
    "            ))               \n",
    "        if truncate:\n",
    "            self.text = self.text[:20000]\n",
    "        self.text_count = len(self.text)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.text_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.text[item]\n",
    "    \n",
    "dataset = ImdbNeg(df_neg_text['text'], truncate=True, gpt2_type=\"gpt2\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "226ab723-d55e-400b-b322-b5aeef49abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c58ce37-4cfc-42b3-8628-247166c7782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(\n",
    "#     dataset, model, tokenizer,\n",
    "#     batch_size=10, epochs=20, lr=2e-6,\n",
    "#     max_seq_len=1000, warmup_steps=200,\n",
    "#     gpt2_type=\"gpt2-xl\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "#     test_mode=False,save_model_on_epoch=False,\n",
    "# ):\n",
    "#     acc_steps = 100\n",
    "#     # device=torch.device(\"cuda\")\n",
    "#     model = model.to(device)\n",
    "#     model.train()\n",
    "#     t = torch.cuda.get_device_properties(1).total_memory\n",
    "#     r = torch.cuda.memory_reserved(1)\n",
    "#     a = torch.cuda.memory_allocated(1)\n",
    "#     f = r-a  # free inside reserved\n",
    "#     print(t/1000000000)\n",
    "#     print(r/1000000000)\n",
    "#     print(a/1000000000)\n",
    "#     print(f/1000000000)\n",
    "    \n",
    "#     optimizer = optim.RAdam(model.parameters(), lr=lr)\n",
    "#     # scheduler = get_linear_schedule_with_warmup(\n",
    "#     #     optimizer, num_warmup_steps=warmup_steps, num_training_steps=1250*20\n",
    "#     # )\n",
    "\n",
    "#     train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#     loss=0\n",
    "#     accumulating_batch_count = 0\n",
    "#     input_tensor = None\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         count = 0\n",
    "#         print(f\"Training epoch {epoch}\")\n",
    "#         print(loss)\n",
    "#         for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "#             #print(len(train_dataloader))\n",
    "#             (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "#             del entry\n",
    "#             del remainder\n",
    "#             gc.collect()\n",
    "#             if count%10 == 0:\n",
    "#                 print(\"FIRST STEP BELOW\")\n",
    "#                 t = torch.cuda.get_device_properties(1).total_memory\n",
    "#                 r = torch.cuda.memory_reserved(1)\n",
    "#                 a = torch.cuda.memory_allocated(1)\n",
    "#                 f = r-a  # free inside reserved\n",
    "#                 print(t/1000000000)\n",
    "#                 print(r/1000000000)\n",
    "#                 print(a/1000000000)\n",
    "#                 print(f/1000000000)\n",
    "#             if carry_on and idx != len(train_dataloader) - 1:\n",
    "#                 continue\n",
    "\n",
    "#             # input_tensor = input_tensor.to(device)\n",
    "#             outputs = model(input_tensor.to(device), labels=input_tensor.to(device))\n",
    "#             print(outputs)\n",
    "#             loss = outputs[0]\n",
    "#             loss.backward()\n",
    "#             del outputs\n",
    "#             del loss #?\n",
    "#             gc.collect()\n",
    "#             # torch.cuda.empty_cache()\n",
    "#             if count%10 == 0:\n",
    "#                 print(\"AFTER LOSS BACK BELOW\")\n",
    "#                 t = torch.cuda.get_device_properties(1).total_memory\n",
    "#                 r = torch.cuda.memory_reserved(1)\n",
    "#                 a = torch.cuda.memory_allocated(1)\n",
    "#                 f = r-a  # free inside reserved\n",
    "#                 print(t/1000000000)\n",
    "#                 print(r/1000000000)\n",
    "#                 print(a/1000000000)\n",
    "#                 print(f/1000000000)\n",
    "\n",
    "#             if (accumulating_batch_count % batch_size) == 0:\n",
    "#                 optimizer.step()\n",
    "#                 # scheduler.step()\n",
    "#                 optimizer.zero_grad(set_to_none=True)\n",
    "#                 model.zero_grad(set_to_none=True)\n",
    "            \n",
    "#             if count%10 == 0:\n",
    "#                 print(\"AFTER MODEL STEP BELOW\")\n",
    "#                 t = torch.cuda.get_device_properties(1).total_memory\n",
    "#                 r = torch.cuda.memory_reserved(1)\n",
    "#                 a = torch.cuda.memory_allocated(1)\n",
    "#                 f = r-a  # free inside reserved\n",
    "#                 print(t/1000000000)\n",
    "#                 print(r/1000000000)\n",
    "#                 print(a/1000000000)\n",
    "#                 print(f/1000000000)\n",
    "#             accumulating_batch_count += 1\n",
    "#             del input_tensor\n",
    "#             # del outputs\n",
    "#             # del loss #?\n",
    "#             gc.collect()\n",
    "#             # torch.cuda.empty_cache()\n",
    "#             input_tensor = None\n",
    "#             if count%10 == 0:\n",
    "#                 print(\"END EXAMPLE BELOW\")\n",
    "#                 t = torch.cuda.get_device_properties(1).total_memory\n",
    "#                 r = torch.cuda.memory_reserved(1)\n",
    "#                 a = torch.cuda.memory_allocated(1)\n",
    "#                 f = r-a  # free inside reserved\n",
    "#                 print(t/1000000000)\n",
    "#                 print(r/1000000000)\n",
    "#                 print(a/1000000000)\n",
    "#                 print(f/1000000000)\n",
    "#             count+=1\n",
    "#         if save_model_on_epoch:\n",
    "#             torch.save(\n",
    "#                 model.state_dict(),\n",
    "#                 os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "#             )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1df8a7e-4157-4926-9915-0ccb27e441fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(\n",
    "#     dataset, model, tokenizer,\n",
    "#     batch_size=10, epochs=20, lr=2e-6,\n",
    "#     max_seq_len=1000, warmup_steps=200,\n",
    "#     gpt2_type=\"gpt2-xl\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "#     test_mode=False,save_model_on_epoch=False,\n",
    "# ):\n",
    "#     acc_steps = 100\n",
    "#     # device=torch.device(\"cuda\")\n",
    "    \n",
    "#     model = DataParallel(model, device_ids = [4,5,6,7])\n",
    "#     model = model.to(device)\n",
    "#     model.train()\n",
    "\n",
    "#     optimizer = optim.RAdam(model.parameters(), lr=lr)\n",
    "#     # scheduler = get_linear_schedule_with_warmup(\n",
    "#     #     optimizer, num_warmup_steps=warmup_steps, num_training_steps=1250*20\n",
    "#     # )\n",
    "\n",
    "#     train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#     loss=0\n",
    "#     accumulating_batch_count = 0\n",
    "#     input_tensor = None\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "\n",
    "#         print(f\"Training epoch {epoch}\")\n",
    "#         print(loss)\n",
    "#         for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "#             #print(len(train_dataloader))\n",
    "#             (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "#             del entry\n",
    "#             del remainder\n",
    "#             gc.collect()\n",
    "#             if carry_on and idx != len(train_dataloader) - 1:\n",
    "#                 continue\n",
    "\n",
    "#             input_tensor = input_tensor.to(device)\n",
    "#             outputs = model(input_tensor, labels=input_tensor)\n",
    "#             loss = outputs[0]\n",
    "#             loss.backward()\n",
    "#             del input_tensor\n",
    "#             del outputs\n",
    "#             del loss #?\n",
    "#             gc.collect()\n",
    "#             if (accumulating_batch_count % batch_size) == 0:\n",
    "#                 optimizer.step()\n",
    "#                 # scheduler.step()\n",
    "#                 optimizer.zero_grad(set_to_none=True)\n",
    "#                 model.zero_grad(set_to_none=True)\n",
    "\n",
    "#             accumulating_batch_count += 1\n",
    "#             # del input_tensor\n",
    "#             # del outputs\n",
    "#             # del loss #?\n",
    "#             gc.collect()\n",
    "#             input_tensor = None\n",
    "#         if save_model_on_epoch:\n",
    "#             torch.save(\n",
    "#                 model.state_dict(),\n",
    "#                 os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "#             )\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96f01c1c-ff43-479f-adb6-39616a374236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    max_len = float(\"-inf\")\n",
    "    stacked_batch = None\n",
    "    for ten in batch:\n",
    "        if ten.size()[0] > max_len:\n",
    "            max_len = ten.size()[0]\n",
    "    for ten in batch:\n",
    "        cur_ten_len = ten.size()[0]\n",
    "        # running_ten = ten\n",
    "        for cur_ten_idx in range(cur_ten_len, max_len):\n",
    "            # print(type(ten))\n",
    "            ten = torch.cat((ten ,torch.tensor(base_tokenizer.encode(base_tokenizer.eos_token))))\n",
    "        if stacked_batch is None:\n",
    "            stacked_batch = ten.unsqueeze(0)\n",
    "        else:\n",
    "            stacked_batch = torch.cat((stacked_batch, ten.unsqueeze(0)))\n",
    "            \n",
    "    return stacked_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed2068c-9bec-4273-b1b2-823cb25b50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset, model, tokenizer,\n",
    "    batch_size=10, epochs=20, lr=2e-4,\n",
    "    max_seq_len=1000, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "    test_mode=False,save_model_on_epoch=False,\n",
    "):\n",
    "    acc_steps = 100\n",
    "    # device=torch.device(\"cuda\")\n",
    "    model = DataParallel(model, device_ids = [0,1,6,5])\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.RAdam(model.parameters(), lr=lr)\n",
    "    # scheduler = get_linear_schedule_with_warmup(\n",
    "    #     optimizer, num_warmup_steps=warmup_steps, num_training_steps=1250*20\n",
    "    # )\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=pad_collate, shuffle=True)\n",
    "\n",
    "    # train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss=0\n",
    "    accumulating_batch_count = 0\n",
    "    input_tensor = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        # print(loss)\n",
    "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "            \n",
    "            #print(len(train_dataloader))\n",
    "            # print(f\"0 {entry}\")\n",
    "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 1024)\n",
    "            # print(f\"1 {input_tensor}\")\n",
    "            del entry\n",
    "            # print(f\"2 {input_tensor}\")\n",
    "            del remainder\n",
    "            # print(f\"3 {input_tensor}\")\n",
    "            gc.collect()\n",
    "            # print(\"before\")\n",
    "            # print(carry_on)\n",
    "            # print(idx)\n",
    "            # print(len(train_dataloader) - 1)\n",
    "            # print(f\"4 {input_tensor}\")\n",
    "            if carry_on and idx != len(train_dataloader) - 1:\n",
    "                continue\n",
    "            # print(\"after\")\n",
    "            # print(f\"5 {input_tensor}\")\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            outputs = model(input_tensor, labels=input_tensor)\n",
    "            loss = outputs[0]\n",
    "            if idx%100 == 0:\n",
    "                # print()\n",
    "                print(f\"LOSS: {loss}\")\n",
    "            loss.mean().backward()\n",
    "            del input_tensor\n",
    "            del outputs\n",
    "            del loss #?\n",
    "            gc.collect()\n",
    "            if (accumulating_batch_count % batch_size) == 0:\n",
    "                optimizer.step()\n",
    "                # scheduler.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                model.zero_grad(set_to_none=True)\n",
    "\n",
    "            accumulating_batch_count += 1\n",
    "            # del input_tensor\n",
    "            # del outputs\n",
    "            # del loss #?\n",
    "            gc.collect()\n",
    "            input_tensor = None\n",
    "        loss = 0\n",
    "        input_tensor = None\n",
    "        if save_model_on_epoch:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c83f3070-282c-4741-85f2-c84042c93427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.358472704\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# # pos_imdb_model = head_model\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(1).total_memory\n",
    "r = torch.cuda.memory_reserved(1)\n",
    "a = torch.cuda.memory_allocated(1)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38634759-6924-4a03-be08-3df2cd354213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "head_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65189357-d72a-446c-ae3a-5bc3d75265f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.94it/s]/usr/lib/python3/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "200it [01:23,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([5.8261, 4.5044, 4.8357, 5.5281], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:20,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([3.6654, 3.5935, 3.7929, 3.8776], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [04:09,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([3.3441, 3.1247, 3.4756, 3.3919], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:16,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([3.4086, 3.4430, 3.4947, 3.6614], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [04:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:55,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.7697, 2.8197, 2.7508, 2.5440], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.5918, 2.9159, 2.8857, 2.6155], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:15,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.6250, 2.5506, 3.0094, 2.8556], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:53,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.3827, 2.4020, 2.6285, 2.5469], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:31,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.1767, 2.6241, 2.6518, 2.5583], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:58,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:15,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.4532, 2.2628, 1.8266, 2.4121], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:10,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.4300, 2.3417, 2.2481, 2.0538], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:38,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([2.2991, 2.0532, 2.4499, 1.9837], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:32,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.7111, 2.1361, 2.0488, 2.0888], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.9665, 1.7937, 1.9134, 2.1456], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:58,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:10,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5592, 1.7983, 1.6346, 1.7103], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6374, 1.6419, 1.7288, 1.3000], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6908, 1.8974, 1.8691, 1.6042], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:11,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.8463, 1.7117, 1.6782, 1.4941], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:54,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5557, 1.6052, 1.4012, 1.8367], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:33,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6768, 1.6930, 1.3908, 1.5659], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:11,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5138, 1.5441, 1.2982, 1.5887], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:53,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4589, 1.5952, 1.5301, 1.6457], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:32,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.1027, 1.7104, 1.6396, 1.4149], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:10,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5269, 1.7190, 1.4682, 1.3045], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:58,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6453, 1.9099, 1.3486, 1.5821], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:53,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.8172, 1.3270, 1.2186, 1.5614], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:48,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6394, 1.5723, 1.4944, 1.5965], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:58,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:38,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.8441, 1.5318, 1.9909, 1.5077], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:54,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4156, 1.3132, 1.9965, 1.6222], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:15,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.1921, 1.4663, 1.6726, 1.4600], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:53,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5131, 1.3621, 1.4246, 1.5446], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:32,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5269, 1.1430, 1.4094, 1.4727], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:11,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5277, 1.5512, 1.6455, 1.3378], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:58,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:32,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.1620, 1.3284, 1.5482, 1.4172], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:10,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6236, 1.5058, 1.4188, 1.3879], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5559, 1.3788, 1.3851, 1.4379], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.2447, 1.4914, 1.4983, 1.4755], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:53,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4480, 1.6165, 1.4852, 1.5314], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:32,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4047, 1.4787, 1.5053, 1.4998], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.3877, 1.2420, 1.7214, 1.6258], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:38,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5757, 1.6121, 1.3737, 1.3213], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:55,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.5054, 1.3546, 1.5220, 1.4846], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4471, 1.4601, 1.3166, 1.4223], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:38,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.2065, 1.4745, 1.2715, 1.4016], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:16,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.4244, 1.3239, 1.4491, 1.5601], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:11,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6961, 1.2421, 1.4873, 1.7386], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6097, 1.4309, 1.5568, 1.5746], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:11,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.3172, 1.5415, 1.2162, 1.5541], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:49,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: tensor([1.6983, 1.5682, 1.3597, 1.3311], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [03:59,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# neg_imdb_model = train(dataset, head_model, base_tokenizer, epochs = 1, max_seq_len=1000, batch_size=10)\n",
    "neg_imdb_model = train(dataset, head_model, base_tokenizer, epochs = 20,  max_seq_len=1000, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f08273-9841-42c0-b613-d70a36c29b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(head_model.state_dict(), \"/home/ubuntu/small_neg_1024\")\n",
    "torch.save(head_model.state_dict(), \"/home/ubuntu/small_neg_midterm_version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7009f1cd-fddd-4c61-9dfc-eec409b7f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.358472704\n",
      "29.041360896\n",
      "1.009902592\n",
      "28.031458304\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52c2a7-7488-4315-9df3-46b6463a39cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
