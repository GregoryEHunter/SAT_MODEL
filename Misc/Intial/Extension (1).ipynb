{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882601a-87b4-49c1-9607-062ac9ef6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import torch\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaModel\n",
    "import math\n",
    "import pandas as pd\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80549f8e-f25e-4f41-95e9-f013d4e01f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3125af-ff95-4814-ba24-ae151ecfa417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "head_model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "for param in head_model.parameters():\n",
    "    \n",
    "   param.requires_grad = False\n",
    "\n",
    "\n",
    "lm_head = head_model.lm_head\n",
    "\n",
    "# head_transformer = head_model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e587393-a31f-4741-8c51-6a9b59fa58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Roberta_model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732bb66-cdd4-45a4-9423-7fa0493eab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionSingle(nn.Module):\n",
    "    # def __init__(self, max_length):\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim = None):\n",
    "        \"\"\"\n",
    "        Single head cross attention block scaled\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.e_dim = encoder_dim\n",
    "        self.d_dim = decoder_dim\n",
    "        if attention_dim is None:\n",
    "            self.attention_dim = decoder_dim\n",
    "        else:\n",
    "            self.attention_dim = attention_dim\n",
    "        \n",
    "        self.WQ = torch.randn((self.d_dim, self.attention_dim), requires_grad=True).to(device)\n",
    "        self.WK = torch.randn((self.e_dim, self.attention_dim), requires_grad=True).to(device)\n",
    "        self.WV = torch.randn((self.e_dim, self.attention_dim), requires_grad=True).to(device)\n",
    "        self.softmax = nn.Softmax(dim=1).to(device)\n",
    "        \n",
    "\n",
    "    def forward(self, encoder_x, decoder_x):\n",
    "        \n",
    "        #print(f\"self.WQ: {self.WQ}\")\n",
    "        Q = torch.mm(decoder_x.to(device), self.WQ ).to(device)\n",
    "        #print(f\"Q shape {Q.shape}\")\n",
    "        #print(f\"Q {Q}\")\n",
    "        K = torch.mm(encoder_x.to(device), self.WK ).to(device)\n",
    "        #print(f\"K shape {K.shape}\")\n",
    "        #print(f\"K {K}\")\n",
    "        V = torch.mm(encoder_x.to(device), self.WV ) .to(device)\n",
    "        #print(f\"V shape {V.shape}\")\n",
    "        #print(f\"V {V}\")\n",
    "        QKT = torch.mm(Q, K.t()).to(device)\n",
    "        #print(f\"QKT shape {QKT.shape}\")\n",
    "        #print(f\"QKT  {QKT}\")\n",
    "      \n",
    "        # Q d_lenXd_dim\n",
    "        # K e_lenXd_dim\n",
    "        # V e_lenXd_dim\n",
    "        QKT_div = torch.div(QKT,math.sqrt(self.d_dim))\n",
    "        \n",
    "        SM = self.softmax(QKT_div).to(device) # may need the div from my earlier transformer\n",
    "        #print(f\"SM  {SM}\")\n",
    "        \n",
    "        attention = torch.mm(SM, V).to(device) \n",
    "        #print(f\"attention shape {attention.shape}\")\n",
    "        return attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d5237-6383-4993-b811-5694a8855a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposedModel(nn.Module):\n",
    "    # def __init__(self, max_length):\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim = None):\n",
    "        \"\"\"\n",
    "        Part by part feed forward\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.e_dim = encoder_dim\n",
    "        self.d_dim = decoder_dim\n",
    "        if attention_dim is None:\n",
    "            self.attention_dim = decoder_dim\n",
    "        else:\n",
    "            self.attention_dim = attention_dim\n",
    "        self.cross_a = CrossAttentionSingle(self.e_dim, self.d_dim, self.attention_dim).to(device)\n",
    "        self.FF = nn.Linear(self.attention_dim, self.d_dim).to(device)\n",
    "        self.Relu = nn.ReLU().to(device)\n",
    "        self.FF2 = nn.Linear(self.d_dim, self.d_dim).to(device)\n",
    "        self.lm_head = lm_head\n",
    "        \n",
    "    def forward(self, encoder_x, decoder_x):\n",
    "        attention = self.cross_a(encoder_x, decoder_x)\n",
    "        adjustment = self.FF(attention)\n",
    "        non_lin_adjustment = self.Relu(adjustment)\n",
    "        adjustment = self.FF2(non_lin_adjustment)\n",
    "        adjusted_output = adjustment + decoder_x\n",
    "        # ######\n",
    "        # adjusted_output = decoder_x\n",
    "        # ######\n",
    "        output = self.lm_head(adjusted_output)\n",
    "        # print(attention.shape)\n",
    "        # print(adjusted_output.shape)\n",
    "        # print(output.shape)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ac341-5dcf-4a64-ae83-079e8b499b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I work as a data scientist\"\n",
    "# text_ids = tokenizer.encode(text, return_tensors = 'pt').to(device)\n",
    "# print(text_ids)\n",
    "# # logits = head_transformer(text_ids).last_hidden_state.squeeze()\n",
    "# logits = head_model(text_ids).logits\n",
    "# logits_shape = logits.shape\n",
    "# print(f\"decoder logits shape {logits_shape}\")\n",
    "# print(f\"decoder logits sum {torch.sum(logits, dim = 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ec36d-8948-4f7b-9335-6c999535252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm_head(logits).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23adaf-ab19-4f6b-bdfd-565ca6b3111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_tokenized = R_tokenizer(text, return_tensors = 'pt')\n",
    "# R_embed = Roberta_model(**R_tokenized).last_hidden_state.squeeze()\n",
    "# R_embed_shape = R_embed.shape\n",
    "# print(f\"Roberta shape {R_embed_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64abf8b-a353-4aa1-9b32-c724f64c344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = ProposedModel(R_embed_shape[1], logits_shape[1], attention_dim = None)\n",
    "# # test_model.forward(R_embed, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e10c7-e9e2-47d3-a853-47686fa2a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_train = pd.read_csv('train.tsv.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31bf3c-5b39-423d-bf42-282fe6cf2e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
       "      <td>18</td>\n",
       "      <td>edsb738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>6</td>\n",
       "      <td>ee7fdou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>3</td>\n",
       "      <td>efgbhks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>13</td>\n",
       "      <td>ed1naf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>17</td>\n",
       "      <td>eecwmbq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0   1        2\n",
       "0      My favourite food is anything I didn't have to...  27  eebbqej\n",
       "1      Now if he does off himself, everyone will thin...  27  ed00q6i\n",
       "2                         WHY THE FUCK IS BAYLESS ISOING   2  eezlygj\n",
       "3                            To make her feel threatened  14  ed7ypvh\n",
       "4                                 Dirty Southern Wankers   3  ed0bdzj\n",
       "...                                                  ...  ..      ...\n",
       "43405  Added you mate well I’ve just got the bow and ...  18  edsb738\n",
       "43406  Always thought that was funny but is it a refe...   6  ee7fdou\n",
       "43407  What are you talking about? Anything bad that ...   3  efgbhks\n",
       "43408            More like a baptism, with sexy results!  13  ed1naf8\n",
       "43409                                    Enjoy the ride!  17  eecwmbq\n",
       "\n",
       "[43410 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb1458-51d4-4d32-b08c-5955b55262c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions_train.values[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbe8ee-8b67-4263-9c7b-a18925580dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go_emotions_train[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97d6c0-4239-4ce9-8323-13a04f08ebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f85ef-c338-4bcf-83e9-1f8490ce6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emotions_dict_emoToidx = {} # emo -> idx\n",
    "emotions_dict_idxToemo = {} # idx -> emo\n",
    "for idx, val in enumerate(go_emotions_train.values):\n",
    "    for emotion in val[1].split(','):\n",
    "        if emotion not in emotions_dict_emoToidx:\n",
    "            emotions_dict_emoToidx[emotion] = []\n",
    "        emotions_dict_emoToidx[emotion].append(idx)\n",
    "        \n",
    "        if idx not in emotions_dict_idxToemo:\n",
    "            emotions_dict_idxToemo[idx] = []\n",
    "        emotions_dict_idxToemo[idx].append(emotion)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c77d8-d034-4817-b248-f61efaed0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go_emotions_train.values[emotions_dict['27']]\n",
    "#print(go_emotions_train.values[emotions_dict_emoToidx['6']])\n",
    "# print(emotions_dict_idxToemo[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3f7be-db56-4f32-afbe-550830730a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab892f7-5762-4037-b53f-5c5447ea6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(emo_gpt2-xl.pt, \n",
    "# emo_gpt_embed = torch.load('emo_gpt2-xl.pt', map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40246a-3761-4152-9a12-9db144be13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emo_roberta_embed = torch.load('emo_Roberta.pt', map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04460432-428b-4c45-a6b6-81829be505e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "6.43825664\n",
      "6.421954048\n",
      "0.016302592\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ea760-c35a-4885-9c74-bf69448d8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_inputs(context_tensors, generator_logits):\n",
    "    context = torch.load(context_tensors, map_location=lambda storage, loc: storage.cuda(0))\n",
    "    logits = torch.load(generator_logits, map_location=lambda storage, loc: storage.cuda(0))\n",
    "    return context, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e0e59-efea-4e28-ad76-a881950843fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_roberta_embed, emo_gpt_embed = load_model_inputs('emo_Roberta.pt', 'emo_gpt2-xl.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a73308-d686-42d6-b58a-49a435e604e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "14.506000384\n",
      "14.483106304\n",
      "0.02289408\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8977c9-0ac1-432c-a8bc-9381d6d0c805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dddbeaa-2ae7-4245-adf4-1488484bbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = ProposedModel(emo_roberta_embed[0].shape[1],emo_gpt_embed[0].shape[1], attention_dim = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e1c05-9b41-409a-ad27-0a40472c4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(emo_roberta_embed[0].shape[1])\n",
    "print(emo_gpt_embed[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a69550-0bbe-4995-bd62-64745dc56bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.forward(emo_roberta_embed[0], emo_gpt_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf9626-b152-4158-abee-251976dfcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35aca54-adf6-42ac-bf22-df31500dc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(gpt_embeddings, tokenizer, go_emotions_train):\n",
    "    emotions_dict_emoToidx = {} # emo -> idx\n",
    "    emotions_dict_idxToemo = {} # idx -> emo\n",
    "    for idx, val in enumerate(go_emotions_train.values):\n",
    "        for emotion in val[1].split(','):\n",
    "            if emotion not in emotions_dict_emoToidx:\n",
    "                emotions_dict_emoToidx[emotion] = []\n",
    "            emotions_dict_emoToidx[emotion].append(idx)\n",
    "\n",
    "            if idx not in emotions_dict_idxToemo:\n",
    "                emotions_dict_idxToemo[idx] = []\n",
    "            emotions_dict_idxToemo[idx].append(emotion)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_data_tuples = []\n",
    "    count = 0\n",
    "    for example in range(len(gpt_embeddings)):\n",
    "        emotion_list = emotions_dict_idxToemo[example]\n",
    "        for emotion in emotion_list:\n",
    "            text = go_emotions_train.values[example][0]\n",
    "\n",
    "                \n",
    "            text_ids = tokenizer.encode(text, return_tensors = 'pt', truncation=True).to(device) ### GPU USAGE THAT CAN BE MADE MORE EFFICIENT\n",
    "            \n",
    "            # text_id_shape = text_ids.shape\n",
    "            \n",
    "            # if count == 3487:\n",
    "            #     print(text_id_shape)\n",
    "            #     print(gpt_embeddings[example].shape)\n",
    "            # if count == 1:\n",
    "            #     print(text_id_shape)\n",
    "            #     print(gpt_embeddings[example].shape)\n",
    "            \n",
    "            if len(gpt_embeddings[example].shape) == 1:\n",
    "                print(gpt_embeddings[example].shape)\n",
    "                gpt_embeddings[example] = torch.reshape(gpt_embeddings[example], (1, len(gpt_embeddings[example])))\n",
    "                print(gpt_embeddings[example].shape)\n",
    "                \n",
    "            train_data_tuples.append((gpt_embeddings[example], emotion, text_ids))\n",
    "            count += 1\n",
    "    return train_data_tuples\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c4220-7055-40e3-ae5e-f783d8b51a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "14.506000384\n",
      "14.483106304\n",
      "0.02289408\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b8a49-6b11-4f36-b5ff-5306bf4d7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_context, val_logits = load_model_inputs('emo_roberta_dev.pt', 'emo_gpt2_dev.pt')\n",
    "dev_emo_DF = pd.read_csv('dev.tsv.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf2550-fbe9-4e90-b208-3cdc439dc3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "15.512633344\n",
      "15.486588416\n",
      "0.026044928\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e893ba-ca60-40c9-ac84-21db43b01bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(gpt_embeddings, tokenizer, data, num_context_samples, context_embeddings):\n",
    "    emotions_dict_emoToidx = {} # emo -> idx\n",
    "    emotions_dict_idxToemo = {} # idx -> emo\n",
    "    for idx, val in enumerate(data.values):\n",
    "        for emotion in val[1].split(','):\n",
    "            if emotion not in emotions_dict_emoToidx:\n",
    "                emotions_dict_emoToidx[emotion] = []\n",
    "            emotions_dict_emoToidx[emotion].append(idx)\n",
    "\n",
    "            if idx not in emotions_dict_idxToemo:\n",
    "                emotions_dict_idxToemo[idx] = []\n",
    "            emotions_dict_idxToemo[idx].append(emotion)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_data_tuples = []\n",
    "    count = 0\n",
    "    for example in range(len(gpt_embeddings)):\n",
    "        emotion_list = emotions_dict_idxToemo[example]\n",
    "        for emotion in emotion_list:\n",
    "            text = data.values[example][0]\n",
    "\n",
    "                \n",
    "            text_ids = tokenizer.encode(text, return_tensors = 'pt', truncation=True).to(device) # ### GPU USAGE THAT CAN BE MADE MORE EFFICIENT\n",
    "            \n",
    "            emotion_idxs = emotions_dict_emoToidx[emotion]\n",
    "            context_sample_list = []\n",
    "            for context_doc in range(num_context_samples): # without network  takes 23 seconds\n",
    "                # sample average and stack document samples from a particular emotion\n",
    "                context_sample_idx = random.sample(emotion_idxs,1)\n",
    "                #print(context_sample_idx)\n",
    "                single_context_sample = context_embeddings[context_sample_idx[0]]\n",
    "                mean_of_sample = torch.mean(single_context_sample, 0)\n",
    "                #\n",
    "                # mean_of_sample = torch.randn(mean_of_sample.size())\n",
    "                # mean_of_sample = torch.zeros(mean_of_sample.size())\n",
    "                #\n",
    "                context_sample_list.append(mean_of_sample)\n",
    "            agregated_stacked_context_sample = torch.stack(context_sample_list, dim = 0)\n",
    "            \n",
    "            if len(gpt_embeddings[example].shape) == 1:\n",
    "                print(gpt_embeddings[example].shape)\n",
    "                gpt_embeddings[example] = torch.reshape(gpt_embeddings[example], (1, len(gpt_embeddings[example])))\n",
    "                print(gpt_embeddings[example].shape)\n",
    "                \n",
    "            test_data_tuples.append((gpt_embeddings[example], emotion, text_ids, agregated_stacked_context_sample))\n",
    "            count += 1\n",
    "    return test_data_tuples\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d27f96-d0ec-4e7a-80ca-d02da75361b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n",
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n"
     ]
    }
   ],
   "source": [
    "gpt_embeddings_emotion_tuples = prepare_train_data(emo_gpt_embed, tokenizer, go_emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab1c05-b022-454c-a18a-416eb46be621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "15.514730496\n",
      "15.512767488\n",
      "0.001963008\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cba49-f95f-418a-a67c-86bae80f83a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "15.514730496\n",
      "15.512767488\n",
      "0.001963008\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0af57-f501-4494-a739-44b25da1e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "gpt_dev_logits = []\n",
    "for sen in dev_emo_DF.values:\n",
    "    gpt_tokenized = tokenizer.encode(sen[0], return_tensors = 'pt').to(device)\n",
    "    if gpt_tokenized.shape[1] == 1:\n",
    "        continue\n",
    "    base_output = head_model(gpt_tokenized, labels = gpt_tokenized)\n",
    "    loss += base_output.loss.to('cpu')\n",
    "    #gpt_dev_logits.append(head_model.transformer(gpt_tokenized))\n",
    "    \n",
    "    del gpt_tokenized\n",
    "    del base_output\n",
    "    \n",
    "    print(\".\", end='')\n",
    "average_loss = loss/len(dev_emo_DF.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16984f-b189-4987-afbd-caf9ed7af99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4947)\n"
     ]
    }
   ],
   "source": [
    "print(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc41eb6-e2c9-4b47-bcbe-21eec8752b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915450ef-4953-4618-b19b-ee5be40c6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "15.514730496\n",
      "15.512767488\n",
      "0.001963008\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d02bc-0689-442e-9402-17955f5eaedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4947)\n"
     ]
    }
   ],
   "source": [
    "print(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff96b3-2b9d-4116-9017-ee5621b0896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600])\n",
      "torch.Size([1, 1600])\n"
     ]
    }
   ],
   "source": [
    "dev_prepared = prepare_test_data(val_logits, tokenizer, dev_emo_DF, 100, val_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c5bb9-cc25-4992-a3de-1c0d73fed1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "18.190696448\n",
      "18.12928256\n",
      "0.061413888\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02ecfe-ec33-4255-ac52-3675fdeed34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, context_embeddings, gpt_embeddings_emotion_tuples, num_context_samples, epochs, dev_tuples, num_examples=None):\n",
    "    \n",
    "    CELoss = nn.CrossEntropyLoss()\n",
    "    random.shuffle(gpt_embeddings_emotion_tuples)\n",
    "    if num_examples is not None:\n",
    "        gpt_embeddings_emotion_tuples = gpt_embeddings_emotion_tuples[:num_examples]\n",
    "    print(f\"Num examples: {len(gpt_embeddings_emotion_tuples)}\")\n",
    "    total_example_count = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        random.shuffle(gpt_embeddings_emotion_tuples)\n",
    "        count = 0\n",
    "        ag_loss = 0\n",
    "        ag_loss_epoch = 0\n",
    "        for gpt_idx_emo_tup in gpt_embeddings_emotion_tuples:\n",
    "            emotion = gpt_idx_emo_tup[1]\n",
    "            \n",
    "            #print(emotion) \n",
    "            \n",
    "            emotion_idxs = emotions_dict_emoToidx[emotion]\n",
    "\n",
    "            # for idx in emotion_idxs:\n",
    "            context_sample_list = []\n",
    "            for context_doc in range(num_context_samples): # without network  takes 23 seconds\n",
    "                # sample average and stack document samples from a particular emotion\n",
    "                context_sample_idx = random.sample(emotion_idxs,1)\n",
    "                #print(context_sample_idx)\n",
    "                single_context_sample = context_embeddings[context_sample_idx[0]]\n",
    "                mean_of_sample = torch.mean(single_context_sample, 0)\n",
    "                #\n",
    "                # mean_of_sample = torch.randn(mean_of_sample.size())\n",
    "                # mean_of_sample = torch.zeros(mean_of_sample.size())\n",
    "                #\n",
    "                context_sample_list.append(mean_of_sample)\n",
    "            agregated_stacked_context_sample = torch.stack(context_sample_list, dim = 0)\n",
    "            \n",
    "            # print(agregated_stacked_context_sample.shape)\n",
    "            # print(gpt_idx_emo_tups[0].shape)\n",
    "#             if count == 3487:\n",
    "#                 print(f\"Count: {count} Text ids: {gpt_idx_emo_tup[2]}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            network_output = model(agregated_stacked_context_sample, gpt_idx_emo_tup[0])\n",
    "            \n",
    "            # https://huggingface.co/transformers/v3.5.1/_modules/transformers/modeling_gpt2.html referenced from here\n",
    "            #print(gpt_idx_emo_tup[2].shape[1])\n",
    "            if gpt_idx_emo_tup[2].shape[1] == 1:\n",
    "                #print(\"ONE text id?\")\n",
    "                #print(gpt_idx_emo_tup[2].shape[1])\n",
    "                continue\n",
    "            shifted_network_output = network_output[..., :-1, :].contiguous()\n",
    "            shifted_text_ids = gpt_idx_emo_tup[2][..., 1:].contiguous()\n",
    "            loss = CELoss(shifted_network_output.view(-1, shifted_network_output.size(-1)), shifted_text_ids.view(-1))\n",
    "            ag_loss += loss\n",
    "            ag_loss_epoch += loss\n",
    "            total_example_count += 1\n",
    "            ## extra stuff from before\n",
    "            # print(f\"True output: {torch.sum(true_output,dim =1)}\")\n",
    "            # print(f\"network_output: {network_output.shape}\")\n",
    "            # print(f\"True output: {true_output.shape}\")\n",
    "            # print(f\"network_output: {network_output.squeeze().shape}\")\n",
    "            # print(f\"True output: {true_output.squeeze().shape}\")\n",
    "            # print(f\"network_output: {torch.sum(network_output,dim =1)}\")\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if count%1000 == 0:\n",
    "                # print(f\"For Epoch: {epoch}, Example: {count}\")\n",
    "                # print(f\"TRAIN LOSS: {ag_loss/1000}\")\n",
    "                print(\".\", end='')\n",
    "                # ag_loss = 0\n",
    "            count+=1\n",
    "            \n",
    "        model.eval()\n",
    "        CELoss_dev = nn.CrossEntropyLoss()\n",
    "        dev_loss_acum = 0\n",
    "        for dev_example in dev_tuples:\n",
    "            # print(dev_example[3].shape)\n",
    "            # print(dev_example[0].shape)\n",
    "            # print(gpt_idx_emo_tup[0].shape)\n",
    "            \n",
    "            dev_network_output = model(dev_example[3], dev_example[0])\n",
    "            \n",
    "#             # https://huggingface.co/transformers/v3.5.1/_modules/transformers/modeling_gpt2.html referenced from here\n",
    "#             #print(gpt_idx_emo_tup[2].shape[1])\n",
    "            if dev_example[2].shape[1] == 1:\n",
    "                #print(\"ONE text id?\")\n",
    "                #print(gpt_idx_emo_tup[2].shape[1])\n",
    "                continue\n",
    "            shifted_network_output_dev = dev_network_output[..., :-1, :].contiguous()\n",
    "            shifted_text_ids_dev = dev_example[2][..., 1:].contiguous()\n",
    "            dev_loss = CELoss_dev(shifted_network_output_dev.view(-1, shifted_network_output_dev.size(-1)), shifted_text_ids_dev.view(-1))\n",
    "            # print(dev_loss.float())\n",
    "            dev_loss_acum += dev_loss.item()\n",
    "        full_dev_loss = dev_loss_acum / len(dev_tuples)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            if epoch == 0:\n",
    "                print(f\"FIRST epoch: {epoch}, Total Examples: {total_example_count}\")\n",
    "                print(f\"TRAIN LOSS: {ag_loss_epoch/len(gpt_embeddings_emotion_tuples)}\")\n",
    "                print(f\"DEV LOSS: {full_dev_loss}\")\n",
    "                print(\"----------------------------------------\")\n",
    "            else:\n",
    "                print(f\"For Epoch: {epoch}, Total Examples: {total_example_count}\")\n",
    "                print(f\"TRAIN LOSS: {ag_loss_epoch/len(gpt_embeddings_emotion_tuples)}\")\n",
    "                print(f\"DEV LOSS: {full_dev_loss}\")\n",
    "                print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e8568-890c-476e-ab21-b89dcb859249",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = ProposedModel(emo_roberta_embed[0].shape[1],emo_gpt_embed[0].shape[1], attention_dim = None)\n",
    "# optimizer = optim.Adam(test_model.parameters(), lr=0.00001,  weight_decay=0.001)\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=0.00001,  weight_decay=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567fe9b-4304-43f9-a84b-fd624b0791cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "18.253611008\n",
      "18.173123072\n",
      "0.080487936\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0dd6e-d662-450e-a50f-095fcd6c5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(test_model, optimizer, emo_roberta_embed, gpt_embeddings_emotion_tuples, 100, 100, dev_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34b357-98d5-4d35-9eba-90e3ca21598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "20B_waiting.ipynb      SimpleFineTune.ipynb  history.ipynb\n",
      "Emot_get_embeds.ipynb  Split_emo_data.ipynb  neg.zip\n",
      "Extension.ipynb        Training_ouput\t     notebook_file.ipynb\n",
      "FineTuneText\t       __pycache__\t     pos.zip\n",
      "GPT-2_parts.ipynb      data\t\t     pos_finetune_lam_try.ipynb\n",
      "Generation.ipynb       dev.tsv.txt\t     pytorch-transformers\n",
      "IMDB_train\t       emo_Roberta.pt\t     records.txt\n",
      "K2-Extension.ipynb     emo_gpt2-xl.pt\t     records_extended.txt\n",
      "Model_Import.py        emo_gpt2_dev.pt\t     test.tsv.txt\n",
      "Models\t\t       emo_neo1_3.pt\t     train.tsv.txt\n",
      "README.md\t       emo_neo2_7.pt\n",
      "RoBERTa_test.ipynb     emo_roberta_dev.pt\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2e192-8142-4d6d-bba2-b9ffad98fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_model.state_dict(), '/home/ubuntu/Models/Emo_100_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c615f5f-1678-43f6-a3ce-2d73947afad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I work as a data scientist\"\n",
    "# text_ids = tokenizer.encode(text, return_tensors = 'pt').to(device)\n",
    "# print(text_ids)\n",
    "# # logits = head_transformer(text_ids).last_hidden_state.squeeze()\n",
    "# logits = head_model(text_ids).logits\n",
    "# logits_shape = logits.shape\n",
    "# print(f\"decoder logits shape {logits_shape}\")\n",
    "# print(f\"decoder logits sum {torch.sum(logits, dim = 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188234a1-a55f-4cb6-910e-d0dff35f21bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "18.253611008\n",
      "18.173123072\n",
      "0.080487936\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcb5ea-952f-4654-b1bb-d929e665953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dev_emo_DF.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481d3ce-dd3d-4a64-9f27-53d6287c9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ones(model, optimizer, context_embeddings, gpt_embeddings_emotion_tuples, num_context_samples, epochs, dev_tuples, num_examples=None):\n",
    "    \n",
    "    CELoss = nn.CrossEntropyLoss()\n",
    "    random.shuffle(gpt_embeddings_emotion_tuples)\n",
    "    if num_examples is not None:\n",
    "        gpt_embeddings_emotion_tuples = gpt_embeddings_emotion_tuples[:num_examples]\n",
    "    print(f\"Num examples: {len(gpt_embeddings_emotion_tuples)}\")\n",
    "    total_example_count = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        random.shuffle(gpt_embeddings_emotion_tuples)\n",
    "        count = 0\n",
    "        ag_loss = 0\n",
    "        ag_loss_epoch = 0\n",
    "        for gpt_idx_emo_tup in gpt_embeddings_emotion_tuples:\n",
    "            emotion = gpt_idx_emo_tup[1]\n",
    "            \n",
    "            #print(emotion) \n",
    "            \n",
    "            emotion_idxs = emotions_dict_emoToidx[emotion]\n",
    "\n",
    "            # for idx in emotion_idxs:\n",
    "            context_sample_list = []\n",
    "            for context_doc in range(num_context_samples): # without network  takes 23 seconds\n",
    "                # sample average and stack document samples from a particular emotion\n",
    "                context_sample_idx = random.sample(emotion_idxs,1)\n",
    "                #print(context_sample_idx)\n",
    "                single_context_sample = context_embeddings[context_sample_idx[0]]\n",
    "                mean_of_sample = torch.mean(single_context_sample, 0)\n",
    "                #\n",
    "                # mean_of_sample = torch.randn(mean_of_sample.size())\n",
    "                mean_of_sample = torch.ones(mean_of_sample.size())\n",
    "                #\n",
    "                context_sample_list.append(mean_of_sample)\n",
    "            agregated_stacked_context_sample = torch.stack(context_sample_list, dim = 0)\n",
    "            \n",
    "            # print(agregated_stacked_context_sample.shape)\n",
    "            # print(gpt_idx_emo_tups[0].shape)\n",
    "#             if count == 3487:\n",
    "#                 print(f\"Count: {count} Text ids: {gpt_idx_emo_tup[2]}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            network_output = model(agregated_stacked_context_sample, gpt_idx_emo_tup[0])\n",
    "            \n",
    "            # https://huggingface.co/transformers/v3.5.1/_modules/transformers/modeling_gpt2.html referenced from here\n",
    "            #print(gpt_idx_emo_tup[2].shape[1])\n",
    "            if gpt_idx_emo_tup[2].shape[1] == 1:\n",
    "                #print(\"ONE text id?\")\n",
    "                #print(gpt_idx_emo_tup[2].shape[1])\n",
    "                continue\n",
    "            shifted_network_output = network_output[..., :-1, :].contiguous()\n",
    "            shifted_text_ids = gpt_idx_emo_tup[2][..., 1:].contiguous()\n",
    "            loss = CELoss(shifted_network_output.view(-1, shifted_network_output.size(-1)), shifted_text_ids.view(-1))\n",
    "            ag_loss += loss\n",
    "            ag_loss_epoch += loss\n",
    "            total_example_count += 1\n",
    "            ## extra stuff from before\n",
    "            # print(f\"True output: {torch.sum(true_output,dim =1)}\")\n",
    "            # print(f\"network_output: {network_output.shape}\")\n",
    "            # print(f\"True output: {true_output.shape}\")\n",
    "            # print(f\"network_output: {network_output.squeeze().shape}\")\n",
    "            # print(f\"True output: {true_output.squeeze().shape}\")\n",
    "            # print(f\"network_output: {torch.sum(network_output,dim =1)}\")\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if count%1000 == 0:\n",
    "                # print(f\"For Epoch: {epoch}, Example: {count}\")\n",
    "                # print(f\"TRAIN LOSS: {ag_loss/1000}\")\n",
    "                print(\".\", end='')\n",
    "                # ag_loss = 0\n",
    "            count+=1\n",
    "            \n",
    "        model.eval()\n",
    "        CELoss_dev = nn.CrossEntropyLoss()\n",
    "        dev_loss_acum = 0\n",
    "        for dev_example in dev_tuples:\n",
    "            # print(dev_example[3].shape)\n",
    "            # print(dev_example[0].shape)\n",
    "            # print(gpt_idx_emo_tup[0].shape)\n",
    "            \n",
    "            dev_network_output = model(dev_example[3], dev_example[0])\n",
    "            \n",
    "#             # https://huggingface.co/transformers/v3.5.1/_modules/transformers/modeling_gpt2.html referenced from here\n",
    "#             #print(gpt_idx_emo_tup[2].shape[1])\n",
    "            if dev_example[2].shape[1] == 1:\n",
    "                #print(\"ONE text id?\")\n",
    "                #print(gpt_idx_emo_tup[2].shape[1])\n",
    "                continue\n",
    "            shifted_network_output_dev = dev_network_output[..., :-1, :].contiguous()\n",
    "            shifted_text_ids_dev = dev_example[2][..., 1:].contiguous()\n",
    "            dev_loss = CELoss_dev(shifted_network_output_dev.view(-1, shifted_network_output_dev.size(-1)), shifted_text_ids_dev.view(-1))\n",
    "            # print(dev_loss.float())\n",
    "            dev_loss_acum += dev_loss.item()\n",
    "        full_dev_loss = dev_loss_acum / len(dev_tuples)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            if epoch == 0:\n",
    "                print(f\"FIRST epoch: {epoch}, Total Examples: {total_example_count}\")\n",
    "                print(f\"TRAIN LOSS: {ag_loss_epoch/len(gpt_embeddings_emotion_tuples)}\")\n",
    "                print(f\"DEV LOSS: {full_dev_loss}\")\n",
    "                print(\"----------------------------------------\")\n",
    "            else:\n",
    "                print(f\"For Epoch: {epoch}, Total Examples: {total_example_count}\")\n",
    "                print(f\"TRAIN LOSS: {ag_loss_epoch/len(gpt_embeddings_emotion_tuples)}\")\n",
    "                print(f\"DEV LOSS: {full_dev_loss}\")\n",
    "                print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9cf8b1-f381-4bbe-95c3-acc30b421506",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model2 = ProposedModel(emo_roberta_embed[0].shape[1],emo_gpt_embed[0].shape[1], attention_dim = None)\n",
    "# optimizer = optim.Adam(test_model.parameters(), lr=0.00001,  weight_decay=0.001)\n",
    "optimizer = optim.Adam(test_model2.parameters(), lr=0.00001,  weight_decay=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51ffeb-7439-4252-b66a-638fe2457d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ones(test_model2, optimizer, emo_roberta_embed, gpt_embeddings_emotion_tuples, 100, 100, dev_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c0467-31a0-4614-b1be-5410cb6fee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "18.295554048\n",
      "18.217946624\n",
      "0.077607424\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4130c6-5684-4495-ba1e-31ef70e8753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_dif_num_context = ProposedModel(emo_roberta_embed[0].shape[1],emo_gpt_embed[0].shape[1], attention_dim = None)\n",
    "\n",
    "optimizer = optim.Adam(test_model_dif_num_context.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9beb7-94cf-408e-b9dd-9c1c70940ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_prepared_10 = prepare_test_data(val_logits, tokenizer, dev_emo_DF, 10, val_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c329d-5346-4dfd-a284-c893c0954901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_prepared_1 = prepare_test_data(val_logits, tokenizer, dev_emo_DF, 1, val_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5be79-a45d-4bd4-b84c-f0bd29182f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 51103\n",
      "....................................................FIRST epoch: 0, Total Examples: 51094\n",
      "TRAIN LOSS: 4.272182941436768\n",
      "DEV LOSS: 4.186780326129127\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 1, Total Examples: 102188\n",
      "TRAIN LOSS: 4.196245193481445\n",
      "DEV LOSS: 4.195555310357701\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 2, Total Examples: 153282\n",
      "TRAIN LOSS: 4.188021183013916\n",
      "DEV LOSS: 4.199080481377889\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 3, Total Examples: 204376\n",
      "TRAIN LOSS: 4.18240213394165\n",
      "DEV LOSS: 4.195852897935152\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 4, Total Examples: 255470\n",
      "TRAIN LOSS: 4.17851448059082\n",
      "DEV LOSS: 4.197913621725707\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 5, Total Examples: 306564\n",
      "TRAIN LOSS: 4.1758317947387695\n",
      "DEV LOSS: 4.202565061373397\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 6, Total Examples: 357658\n",
      "TRAIN LOSS: 4.172914981842041\n",
      "DEV LOSS: 4.207820322399603\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 7, Total Examples: 408752\n",
      "TRAIN LOSS: 4.170884132385254\n",
      "DEV LOSS: 4.202355686250526\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 8, Total Examples: 459846\n",
      "TRAIN LOSS: 4.1689605712890625\n",
      "DEV LOSS: 4.206484795195929\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 9, Total Examples: 510940\n",
      "TRAIN LOSS: 4.1676740646362305\n",
      "DEV LOSS: 4.20476240326992\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 10, Total Examples: 562034\n",
      "TRAIN LOSS: 4.1656694412231445\n",
      "DEV LOSS: 4.207437278391052\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 11, Total Examples: 613128\n",
      "TRAIN LOSS: 4.163918495178223\n",
      "DEV LOSS: 4.210703256259144\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 12, Total Examples: 664222\n",
      "TRAIN LOSS: 4.16304349899292\n",
      "DEV LOSS: 4.205048792087546\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 13, Total Examples: 715316\n",
      "TRAIN LOSS: 4.162454128265381\n",
      "DEV LOSS: 4.21185634804183\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 14, Total Examples: 766410\n",
      "TRAIN LOSS: 4.161566257476807\n",
      "DEV LOSS: 4.216867460436582\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 15, Total Examples: 817504\n",
      "TRAIN LOSS: 4.160495281219482\n",
      "DEV LOSS: 4.210019078776007\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 16, Total Examples: 868598\n",
      "TRAIN LOSS: 4.159376621246338\n",
      "DEV LOSS: 4.215225785157897\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 17, Total Examples: 919692\n",
      "TRAIN LOSS: 4.159262657165527\n",
      "DEV LOSS: 4.20712389749793\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 18, Total Examples: 970786\n",
      "TRAIN LOSS: 4.158476829528809\n",
      "DEV LOSS: 4.213296789099057\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 19, Total Examples: 1021880\n",
      "TRAIN LOSS: 4.157816410064697\n",
      "DEV LOSS: 4.222984149528895\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 20, Total Examples: 1072974\n",
      "TRAIN LOSS: 4.157410144805908\n",
      "DEV LOSS: 4.210854509454162\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 21, Total Examples: 1124068\n",
      "TRAIN LOSS: 4.157131195068359\n",
      "DEV LOSS: 4.208938791067997\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 22, Total Examples: 1175162\n",
      "TRAIN LOSS: 4.1570305824279785\n",
      "DEV LOSS: 4.2102134012783585\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 23, Total Examples: 1226256\n",
      "TRAIN LOSS: 4.155831813812256\n",
      "DEV LOSS: 4.213026857366756\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 24, Total Examples: 1277350\n",
      "TRAIN LOSS: 4.155794143676758\n",
      "DEV LOSS: 4.222630481576098\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 25, Total Examples: 1328444\n",
      "TRAIN LOSS: 4.155450820922852\n",
      "DEV LOSS: 4.214226379243184\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 26, Total Examples: 1379538\n",
      "TRAIN LOSS: 4.155557155609131\n",
      "DEV LOSS: 4.221919178514272\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 27, Total Examples: 1430632\n",
      "TRAIN LOSS: 4.155145645141602\n",
      "DEV LOSS: 4.220968632600898\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 28, Total Examples: 1481726\n",
      "TRAIN LOSS: 4.154313087463379\n",
      "DEV LOSS: 4.214352680373715\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 29, Total Examples: 1532820\n",
      "TRAIN LOSS: 4.153650283813477\n",
      "DEV LOSS: 4.219945616725844\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 30, Total Examples: 1583914\n",
      "TRAIN LOSS: 4.153437614440918\n",
      "DEV LOSS: 4.229936908984259\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 31, Total Examples: 1635008\n",
      "TRAIN LOSS: 4.154150009155273\n",
      "DEV LOSS: 4.221729891483313\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 32, Total Examples: 1686102\n",
      "TRAIN LOSS: 4.154204845428467\n",
      "DEV LOSS: 4.2107247850084\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 33, Total Examples: 1737196\n",
      "TRAIN LOSS: 4.153537750244141\n",
      "DEV LOSS: 4.217932597979856\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 34, Total Examples: 1788290\n",
      "TRAIN LOSS: 4.153533458709717\n",
      "DEV LOSS: 4.222250416800146\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 35, Total Examples: 1839384\n",
      "TRAIN LOSS: 4.153379917144775\n",
      "DEV LOSS: 4.220767048907504\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 36, Total Examples: 1890478\n",
      "TRAIN LOSS: 4.153397083282471\n",
      "DEV LOSS: 4.214090766110764\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 37, Total Examples: 1941572\n",
      "TRAIN LOSS: 4.153288841247559\n",
      "DEV LOSS: 4.216921913511701\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 38, Total Examples: 1992666\n",
      "TRAIN LOSS: 4.152125358581543\n",
      "DEV LOSS: 4.221105009233316\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 39, Total Examples: 2043760\n",
      "TRAIN LOSS: 4.152982711791992\n",
      "DEV LOSS: 4.2321181400536\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 40, Total Examples: 2094854\n",
      "TRAIN LOSS: 4.1526875495910645\n",
      "DEV LOSS: 4.214357329479953\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 41, Total Examples: 2145948\n",
      "TRAIN LOSS: 4.152639389038086\n",
      "DEV LOSS: 4.223344699790859\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 42, Total Examples: 2197042\n",
      "TRAIN LOSS: 4.15242862701416\n",
      "DEV LOSS: 4.220008699002684\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 43, Total Examples: 2248136\n",
      "TRAIN LOSS: 4.151845455169678\n",
      "DEV LOSS: 4.222384356275247\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 44, Total Examples: 2299230\n",
      "TRAIN LOSS: 4.151654243469238\n",
      "DEV LOSS: 4.226000531592339\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 45, Total Examples: 2350324\n",
      "TRAIN LOSS: 4.150857448577881\n",
      "DEV LOSS: 4.227105909361734\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 46, Total Examples: 2401418\n",
      "TRAIN LOSS: 4.151081085205078\n",
      "DEV LOSS: 4.216029213373564\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 47, Total Examples: 2452512\n",
      "TRAIN LOSS: 4.151672840118408\n",
      "DEV LOSS: 4.2207168533323705\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 48, Total Examples: 2503606\n",
      "TRAIN LOSS: 4.152092933654785\n",
      "DEV LOSS: 4.225583639049605\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 49, Total Examples: 2554700\n",
      "TRAIN LOSS: 4.151630401611328\n",
      "DEV LOSS: 4.224611759223161\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 50, Total Examples: 2605794\n",
      "TRAIN LOSS: 4.15083122253418\n",
      "DEV LOSS: 4.228966483137451\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 51, Total Examples: 2656888\n",
      "TRAIN LOSS: 4.151124000549316\n",
      "DEV LOSS: 4.233509839954421\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 52, Total Examples: 2707982\n",
      "TRAIN LOSS: 4.151196002960205\n",
      "DEV LOSS: 4.220931320065241\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 53, Total Examples: 2759076\n",
      "TRAIN LOSS: 4.150763511657715\n",
      "DEV LOSS: 4.23696005738641\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 54, Total Examples: 2810170\n",
      "TRAIN LOSS: 4.150492191314697\n",
      "DEV LOSS: 4.222758611887226\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 55, Total Examples: 2861264\n",
      "TRAIN LOSS: 4.150787830352783\n",
      "DEV LOSS: 4.229711142098268\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 56, Total Examples: 2912358\n",
      "TRAIN LOSS: 4.150608539581299\n",
      "DEV LOSS: 4.236506248912468\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 57, Total Examples: 2963452\n",
      "TRAIN LOSS: 4.15010404586792\n",
      "DEV LOSS: 4.217197971592502\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 58, Total Examples: 3014546\n",
      "TRAIN LOSS: 4.151023864746094\n",
      "DEV LOSS: 4.214534778271723\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 59, Total Examples: 3065640\n",
      "TRAIN LOSS: 4.15026330947876\n",
      "DEV LOSS: 4.2258828181644965\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 60, Total Examples: 3116734\n",
      "TRAIN LOSS: 4.150710105895996\n",
      "DEV LOSS: 4.225255066679563\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 61, Total Examples: 3167828\n",
      "TRAIN LOSS: 4.150363445281982\n",
      "DEV LOSS: 4.219432168124611\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 62, Total Examples: 3218922\n",
      "TRAIN LOSS: 4.149600028991699\n",
      "DEV LOSS: 4.219440191778643\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 63, Total Examples: 3270016\n",
      "TRAIN LOSS: 4.150211334228516\n",
      "DEV LOSS: 4.236826069825869\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 64, Total Examples: 3321110\n",
      "TRAIN LOSS: 4.149786949157715\n",
      "DEV LOSS: 4.22440417578041\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 65, Total Examples: 3372204\n",
      "TRAIN LOSS: 4.149326324462891\n",
      "DEV LOSS: 4.220382371815768\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 66, Total Examples: 3423298\n",
      "TRAIN LOSS: 4.14957857131958\n",
      "DEV LOSS: 4.230844535078375\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 67, Total Examples: 3474392\n",
      "TRAIN LOSS: 4.149768829345703\n",
      "DEV LOSS: 4.2215161393802365\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 68, Total Examples: 3525486\n",
      "TRAIN LOSS: 4.149722099304199\n",
      "DEV LOSS: 4.2239714716388885\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 69, Total Examples: 3576580\n",
      "TRAIN LOSS: 4.150242328643799\n",
      "DEV LOSS: 4.222838415854777\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 70, Total Examples: 3627674\n",
      "TRAIN LOSS: 4.150070667266846\n",
      "DEV LOSS: 4.231710404615417\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 71, Total Examples: 3678768\n",
      "TRAIN LOSS: 4.150021553039551\n",
      "DEV LOSS: 4.219433862260517\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 72, Total Examples: 3729862\n",
      "TRAIN LOSS: 4.149755477905273\n",
      "DEV LOSS: 4.225752843837006\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 73, Total Examples: 3780956\n",
      "TRAIN LOSS: 4.149453163146973\n",
      "DEV LOSS: 4.2316367425514985\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 74, Total Examples: 3832050\n",
      "TRAIN LOSS: 4.1495819091796875\n",
      "DEV LOSS: 4.220363958913331\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 75, Total Examples: 3883144\n",
      "TRAIN LOSS: 4.1493730545043945\n",
      "DEV LOSS: 4.22421415121204\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 76, Total Examples: 3934238\n",
      "TRAIN LOSS: 4.149503707885742\n",
      "DEV LOSS: 4.214675219782094\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 77, Total Examples: 3985332\n",
      "TRAIN LOSS: 4.149740219116211\n",
      "DEV LOSS: 4.236933010377481\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 78, Total Examples: 4036426\n",
      "TRAIN LOSS: 4.149514675140381\n",
      "DEV LOSS: 4.225879391663501\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 79, Total Examples: 4087520\n",
      "TRAIN LOSS: 4.149826526641846\n",
      "DEV LOSS: 4.232176737688178\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 80, Total Examples: 4138614\n",
      "TRAIN LOSS: 4.148216247558594\n",
      "DEV LOSS: 4.224681313377936\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 81, Total Examples: 4189708\n",
      "TRAIN LOSS: 4.150017261505127\n",
      "DEV LOSS: 4.223814522715571\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 82, Total Examples: 4240802\n",
      "TRAIN LOSS: 4.1497802734375\n",
      "DEV LOSS: 4.225470253040425\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 83, Total Examples: 4291896\n",
      "TRAIN LOSS: 4.148910045623779\n",
      "DEV LOSS: 4.232189367314491\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 84, Total Examples: 4342990\n",
      "TRAIN LOSS: 4.14835786819458\n",
      "DEV LOSS: 4.211801631062008\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 85, Total Examples: 4394084\n",
      "TRAIN LOSS: 4.149789810180664\n",
      "DEV LOSS: 4.234898725170701\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 86, Total Examples: 4445178\n",
      "TRAIN LOSS: 4.149310111999512\n",
      "DEV LOSS: 4.242764471541378\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 87, Total Examples: 4496272\n",
      "TRAIN LOSS: 4.149055004119873\n",
      "DEV LOSS: 4.224566251207668\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 88, Total Examples: 4547366\n",
      "TRAIN LOSS: 4.148571014404297\n",
      "DEV LOSS: 4.234650811534316\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 89, Total Examples: 4598460\n",
      "TRAIN LOSS: 4.149760723114014\n",
      "DEV LOSS: 4.213936817758135\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 90, Total Examples: 4649554\n",
      "TRAIN LOSS: 4.149306297302246\n",
      "DEV LOSS: 4.229565195799995\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 91, Total Examples: 4700648\n",
      "TRAIN LOSS: 4.149221420288086\n",
      "DEV LOSS: 4.227203302977601\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 92, Total Examples: 4751742\n",
      "TRAIN LOSS: 4.1491289138793945\n",
      "DEV LOSS: 4.225297948082787\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 93, Total Examples: 4802836\n",
      "TRAIN LOSS: 4.148226261138916\n",
      "DEV LOSS: 4.220959374700968\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 94, Total Examples: 4853930\n",
      "TRAIN LOSS: 4.149636268615723\n",
      "DEV LOSS: 4.237516083977066\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 95, Total Examples: 4905024\n",
      "TRAIN LOSS: 4.148910999298096\n",
      "DEV LOSS: 4.221894788657984\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 96, Total Examples: 4956118\n",
      "TRAIN LOSS: 4.148483753204346\n",
      "DEV LOSS: 4.229286990176921\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 97, Total Examples: 5007212\n",
      "TRAIN LOSS: 4.149050712585449\n",
      "DEV LOSS: 4.219214110314659\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 98, Total Examples: 5058306\n",
      "TRAIN LOSS: 4.1482367515563965\n",
      "DEV LOSS: 4.2266842751574\n",
      "----------------------------------------\n",
      "....................................................For Epoch: 99, Total Examples: 5109400\n",
      "TRAIN LOSS: 4.149598598480225\n",
      "DEV LOSS: 4.229875170670707\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(test_model_dif_num_context, optimizer, emo_roberta_embed, gpt_embeddings_emotion_tuples, 100, 100, dev_prepared_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf21cb3-2d00-4aa0-9f19-b57369a161b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   17756 MB |   18567 MB |  629802 GB |  629785 GB |\n",
      "|       from large pool |    6274 MB |    7083 MB |  603443 GB |  603437 GB |\n",
      "|       from small pool |   11481 MB |   11487 MB |   26359 GB |   26348 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   17756 MB |   18567 MB |  629802 GB |  629785 GB |\n",
      "|       from large pool |    6274 MB |    7083 MB |  603443 GB |  603437 GB |\n",
      "|       from small pool |   11481 MB |   11487 MB |   26359 GB |   26348 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   18802 MB |   18802 MB |   18952 MB |  153600 KB |\n",
      "|       from large pool |    7310 MB |    7310 MB |    7408 MB |  100352 KB |\n",
      "|       from small pool |   11492 MB |   11492 MB |   11544 MB |   53248 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   17739 KB |  312372 KB |  574585 GB |  574585 GB |\n",
      "|       from large pool |   13520 KB |  310551 KB |  547162 GB |  547162 GB |\n",
      "|       from small pool |    4219 KB |   60370 KB |   27423 GB |   27423 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |  187764    |  187896    |     789 M  |     789 M  |\n",
      "|       from large pool |     221    |     252    |      84 M  |      84 M  |\n",
      "|       from small pool |  187543    |  187673    |     704 M  |     704 M  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |  187764    |  187896    |     789 M  |     789 M  |\n",
      "|       from large pool |     221    |     252    |      84 M  |      84 M  |\n",
      "|       from small pool |  187543    |  187673    |     704 M  |     704 M  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |    5939    |    5939    |    5971    |      32    |\n",
      "|       from large pool |     193    |     193    |     199    |       6    |\n",
      "|       from small pool |    5746    |    5746    |    5772    |      26    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       8    |    3616    |  161572 K  |  161572 K  |\n",
      "|       from large pool |       4    |      13    |   68151 K  |   68151 K  |\n",
      "|       from small pool |       4    |    3616    |   93421 K  |   93421 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40752482-4bf3-40eb-b029-f579df2b0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#             print(type(obj), obj.size())\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc415d-99a8-4d31-960a-d6760c331913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
