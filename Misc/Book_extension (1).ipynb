{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a52c8c-bcbd-48d0-93b0-f4aa7a18ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in ./.local/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.8/site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/lib/python3/dist-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./.local/lib/python3.8/site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.8/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./.local/lib/python3.8/site-packages (from sentence-transformers) (4.24.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.8/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from sentence-transformers) (1.23.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/python3/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (from sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.local/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk->sentence-transformers) (7.0)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.8/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.25.8)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/home/ubuntu/.local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='22.3.1'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fca79-9117-4406-a2e0-b37a812e532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "import torch\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaModel\n",
    "import math\n",
    "# import Model_Import\n",
    "import Model_Import_6 ## eating mem ## changed version commented out above\n",
    "from torch import optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa6b04-9190-483f-b869-296d0a44ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a98c73-b0a0-4726-ad62-be081ed5d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36940d20-50e4-4a72-bd8f-847e49810c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "R_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
    "Roberta_model = RobertaModel.from_pretrained(\"roberta-large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2062f935-8a36-4740-82aa-687bdd4d442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9984cb-166d-4231-88e4-6eadb09a8272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And, after boasting this way of my tolerance, I come to the admission that it has a limit.', 'Conduct may be founded on the hard rock or the wet marshes, but after a certain point I don’t care what it’s founded on.', 'When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart.', 'Only Gatsby, the man who gives his name to this book, was exempt from my reaction—Gatsby, who represented everything for which I have an unaffected scorn.', 'If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away.', 'This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the “creative temperament”—it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again.', 'No—Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = \"\"\"And, after boasting this way of my tolerance, I come to the admission\n",
    "that it has a limit. Conduct may be founded on the hard rock or the\n",
    "wet marshes, but after a certain point I don’t care what it’s founded\n",
    "on. When I came back from the East last autumn I felt that I wanted\n",
    "the world to be in uniform and at a sort of moral attention forever; I\n",
    "wanted no more riotous excursions with privileged glimpses into the\n",
    "human heart. Only Gatsby, the man who gives his name to this book, was\n",
    "exempt from my reaction—Gatsby, who represented everything for which I\n",
    "have an unaffected scorn. If personality is an unbroken series of\n",
    "successful gestures, then there was something gorgeous about him, some\n",
    "heightened sensitivity to the promises of life, as if he were related\n",
    "to one of those intricate machines that register earthquakes ten\n",
    "thousand miles away. This responsiveness had nothing to do with that\n",
    "flabby impressionability which is dignified under the name of the\n",
    "“creative temperament”—it was an extraordinary gift for hope, a\n",
    "romantic readiness such as I have never found in any other person and\n",
    "which it is not likely I shall ever find again. No—Gatsby turned out\n",
    "all right at the end; it is what preyed on Gatsby, what foul dust\n",
    "floated in the wake of his dreams that temporarily closed out my\n",
    "interest in the abortive sorrows and short-winded elations of men.\n",
    "\"\"\"\n",
    "text = text.replace('\\n', ' ')\n",
    "sent_text = nltk.sent_tokenize(text)\n",
    "print(sent_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496d665-9297-45c0-a446-1a5e3bdfbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2085f02-a1f8-42f9-9b82-5f51c2bf6644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>Author</td>\n",
       "      <td>Link</td>\n",
       "      <td>ID</td>\n",
       "      <td>Bookshelf</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Extermination of the American Bison</td>\n",
       "      <td>William T. Hornaday</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/17748</td>\n",
       "      <td>17748</td>\n",
       "      <td>Animal</td>\n",
       "      <td>[Illustration: (Inscription) Mr. Theodore Roos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deadfalls and Snares</td>\n",
       "      <td>A. R. Harding</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/34110</td>\n",
       "      <td>34110</td>\n",
       "      <td>Animal</td>\n",
       "      <td>DEADFALLS AND SNARES [Frontispiece: A GOOD DEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artistic Anatomy of Animals</td>\n",
       "      <td>Édouard Cuyer</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/38315</td>\n",
       "      <td>38315</td>\n",
       "      <td>Animal</td>\n",
       "      <td>+---------------------------------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Birds, Illustrated</td>\n",
       "      <td>Color Photography, Vol. 1, No. 1 Various</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/30221</td>\n",
       "      <td>30221</td>\n",
       "      <td>Animal</td>\n",
       "      <td>FROM: THE PRESIDENT OF THE NATIONAL TEACHERS' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On Snake-Poison: Its Action and Its Antidote</td>\n",
       "      <td>A. Mueller</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/32947</td>\n",
       "      <td>32947</td>\n",
       "      <td>Animal</td>\n",
       "      <td>[Illustration] ON SNAKE-POISON. ITS ACTION AND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fifty Years a Hunter and Trapper</td>\n",
       "      <td>E. N. Woodcock</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/34063</td>\n",
       "      <td>34063</td>\n",
       "      <td>Animal</td>\n",
       "      <td>FIFTY YEARS A HUNTER AND TRAPPER [Frontispiece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What Bird is That?</td>\n",
       "      <td>Frank M. Chapman</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/31751</td>\n",
       "      <td>31751</td>\n",
       "      <td>Animal</td>\n",
       "      <td>Online Distributed Proofreading Team at https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fox Trapping: A Book of Instruction Telling Ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/34076</td>\n",
       "      <td>34076</td>\n",
       "      <td>Animal</td>\n",
       "      <td>FOX TRAPPING [Frontispiece: FALL CATCH] FOX TR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Guide for the Study of Animals</td>\n",
       "      <td>Lucas, Shinn, Smallwood, and Whitney</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/34984</td>\n",
       "      <td>34984</td>\n",
       "      <td>Animal</td>\n",
       "      <td>Proofreading Team at https://www.pgdp.net Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Our Vanishing Wild Life: Its Extermination and...</td>\n",
       "      <td>William T. Hornaday</td>\n",
       "      <td>http://www.gutenberg.org/ebooks/13249</td>\n",
       "      <td>13249</td>\n",
       "      <td>Animal</td>\n",
       "      <td>\"_I know no way of judging of the Future but b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0                                               Title   \n",
       "1             The Extermination of the American Bison   \n",
       "2                                Deadfalls and Snares   \n",
       "3                         Artistic Anatomy of Animals   \n",
       "4                                  Birds, Illustrated   \n",
       "5        On Snake-Poison: Its Action and Its Antidote   \n",
       "6                    Fifty Years a Hunter and Trapper   \n",
       "7                                  What Bird is That?   \n",
       "8   Fox Trapping: A Book of Instruction Telling Ho...   \n",
       "9                    A Guide for the Study of Animals   \n",
       "10  Our Vanishing Wild Life: Its Extermination and...   \n",
       "\n",
       "                                           1  \\\n",
       "0                                     Author   \n",
       "1                        William T. Hornaday   \n",
       "2                              A. R. Harding   \n",
       "3                              Édouard Cuyer   \n",
       "4   Color Photography, Vol. 1, No. 1 Various   \n",
       "5                                 A. Mueller   \n",
       "6                             E. N. Woodcock   \n",
       "7                           Frank M. Chapman   \n",
       "8                                        NaN   \n",
       "9       Lucas, Shinn, Smallwood, and Whitney   \n",
       "10                       William T. Hornaday   \n",
       "\n",
       "                                        2      3          4  \\\n",
       "0                                    Link     ID  Bookshelf   \n",
       "1   http://www.gutenberg.org/ebooks/17748  17748     Animal   \n",
       "2   http://www.gutenberg.org/ebooks/34110  34110     Animal   \n",
       "3   http://www.gutenberg.org/ebooks/38315  38315     Animal   \n",
       "4   http://www.gutenberg.org/ebooks/30221  30221     Animal   \n",
       "5   http://www.gutenberg.org/ebooks/32947  32947     Animal   \n",
       "6   http://www.gutenberg.org/ebooks/34063  34063     Animal   \n",
       "7   http://www.gutenberg.org/ebooks/31751  31751     Animal   \n",
       "8   http://www.gutenberg.org/ebooks/34076  34076     Animal   \n",
       "9   http://www.gutenberg.org/ebooks/34984  34984     Animal   \n",
       "10  http://www.gutenberg.org/ebooks/13249  13249     Animal   \n",
       "\n",
       "                                                    5  \n",
       "0                                                Text  \n",
       "1   [Illustration: (Inscription) Mr. Theodore Roos...  \n",
       "2   DEADFALLS AND SNARES [Frontispiece: A GOOD DEA...  \n",
       "3   +---------------------------------------------...  \n",
       "4   FROM: THE PRESIDENT OF THE NATIONAL TEACHERS' ...  \n",
       "5   [Illustration] ON SNAKE-POISON. ITS ACTION AND...  \n",
       "6   FIFTY YEARS A HUNTER AND TRAPPER [Frontispiece...  \n",
       "7   Online Distributed Proofreading Team at https:...  \n",
       "8   FOX TRAPPING [Frontispiece: FALL CATCH] FOX TR...  \n",
       "9   Proofreading Team at https://www.pgdp.net Tran...  \n",
       "10  \"_I know no way of judging of the Future but b...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smal_g_df = pd.read_csv('small_gutenberg_data.csv', header = None)\n",
    "smal_g_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e91abc7-06c6-47af-8607-d48eb1266f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/Darwin_Gatsby/gatsby_raw.txt', 'r') as file:\n",
    "    gatsby = file.read().replace('\\n', ' ')\n",
    "\n",
    "with open('/home/ubuntu/Darwin_Gatsby/origin_of_species_raw.txt', 'r') as file:\n",
    "    origin = file.read().replace('\\n', ' ')\n",
    "    \n",
    "    #Darwin_Gatsby/origin_of_species_raw.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6df135e-1668-4ffa-8085-cc03b8f83ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2439\n",
      "3981\n"
     ]
    }
   ],
   "source": [
    "gatsby_sen_list = nltk.sent_tokenize(gatsby)\n",
    "origin_sen_list = nltk.sent_tokenize(origin)\n",
    "print(len(gatsby_sen_list))\n",
    "print(len(origin_sen_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87b67b8-935c-48b1-afe2-56be2cc31a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿                               I  In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in my mind ever since.\n"
     ]
    }
   ],
   "source": [
    "print(gatsby_sen_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7062b8-1c4b-4bfa-aca3-9355a40b658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_embeddings_with_mean(model, tokenizer, book_sentence_list):\n",
    "    book_embeds = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for sen in book_sentence_list:\n",
    "            if len(sen) == 0:\n",
    "                print(\"empty sentence\")\n",
    "                continue\n",
    "            R_tokenized = tokenizer(sen, return_tensors = 'pt', truncation=True).to(device)\n",
    "            #print(R_tokenized.shape)\n",
    "            R_embed = model(**R_tokenized).last_hidden_state.squeeze()\n",
    "            # print(R_embed.shape)\n",
    "            #print(R_embed.shape)\n",
    "            del R_tokenized\n",
    "            R_embed = torch.mean(R_embed, 0)\n",
    "            R_embed_cpu = R_embed.to('cpu')\n",
    "            del R_embed\n",
    "            book_embeds.append(R_embed_cpu)\n",
    "            if count%1000 == 0:\n",
    "                # t = torch.cuda.get_device_properties(0).total_memory\n",
    "                # r = torch.cuda.memory_reserved(0)\n",
    "                # a = torch.cuda.memory_allocated(0)\n",
    "                # f = r-a  # free inside reserved\n",
    "                # print(t/1000000000)\n",
    "                # print(r/1000000000)\n",
    "                # print(a/1000000000)\n",
    "                # print(f/1000000000)\n",
    "                print(count)\n",
    "            count += 1\n",
    "        return book_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b829c7-3ad5-45c7-a911-24c19a2ef7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_gatsby_embeds = make_context_embeddings_with_mean(Roberta_model, R_tokenizer, gatsby_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8303c-34f7-43e3-926a-25e816fda994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_origin_embeds = make_context_embeddings_with_mean(Roberta_model, R_tokenizer, origin_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33d2d-1ca8-4913-b812-4bb715a23ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(R_gatsby_embeds[0].shape)\n",
    "# print(len(R_gatsby_embeds))\n",
    "# # print(len(R_origin_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015035e-ae36-4cc1-b5f4-0a69c73771a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "# gpt_head_model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "# gpt_head_transformer = gpt_head_model.transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18db49e-8144-4d8a-8fe1-ecd08fccd831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "14.294188032\n",
      "14.265847808\n",
      "0.028340224\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad036333-c827-49ef-8ed2-3b1225366731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_logits(model, tokenizer, book_sentence_list):\n",
    "    logits = []\n",
    "    token_ids = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for sen in book_sentence_list:\n",
    "            if len(sen) == 0:\n",
    "                print(\"empty sentence\")\n",
    "                continue\n",
    "            gpt_tokenized = tokenizer(sen, return_tensors = 'pt', truncation=True).to(device)\n",
    "            gpt_embed = model(**gpt_tokenized).last_hidden_state.squeeze()\n",
    "            gpt_tokenized_cpu = gpt_tokenized.to('cpu')\n",
    "            del gpt_tokenized\n",
    "            token_ids.append(gpt_tokenized_cpu) ## on the cpu!!!!\n",
    "            gpt_embed_cpu = gpt_embed.to('cpu')\n",
    "            del gpt_embed\n",
    "            logits.append(gpt_embed_cpu)\n",
    "            if count%1000 == 0:\n",
    "                # t = torch.cuda.get_device_properties(0).total_memory\n",
    "                # r = torch.cuda.memory_reserved(0)\n",
    "                # a = torch.cuda.memory_allocated(0)\n",
    "                # f = r-a  # free inside reserved\n",
    "                # print(t/1000000000)\n",
    "                # print(r/1000000000)\n",
    "                # print(a/1000000000)\n",
    "                # print(f/1000000000)\n",
    "                print(count)\n",
    "            count += 1\n",
    "            \n",
    "        return logits, token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d605b7-9f39-4287-b0b5-e4fe75e0cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gatsby_logits, gatsby_token_ids = make_logits(Model_Import.head_transformer, Model_Import.tokenizer, gatsby_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4038e-4393-4beb-bfa2-8b7ae90a5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_logits, origin_token_ids = make_logits(Model_Import.head_transformer, Model_Import.tokenizer, origin_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95474948-f6c4-42ec-a0da-f59dc3f70736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gatsby_logits[0].shape)\n",
    "# print(len(gatsby_logits))\n",
    "# # print(len(origin_logits))\n",
    "# print(len(gatsby_token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f576eac-6583-44f5-9c92-01face3cde50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.314694656\n",
      "14.294188032\n",
      "14.265847808\n",
      "0.028340224\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t/1000000000)\n",
    "print(r/1000000000)\n",
    "print(a/1000000000)\n",
    "print(f/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae4ba8-02e6-4b97-b7ac-1baedb2fd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gatsby_token_ids[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99640e61-23f4-4869-aef3-497e43e21e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_style(model, optimizer, context_embeds_list, logits_list, token_ids_list, epochs, num_samples = 100):\n",
    "    CELoss = nn.CrossEntropyLoss()\n",
    "    total_count = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        to_shuffle = list(zip(logits_list, token_ids_list))\n",
    "\n",
    "        random.shuffle(to_shuffle)\n",
    "\n",
    "        logits_list, token_ids_list = zip(*to_shuffle)\n",
    "\n",
    "        model.train()\n",
    "        ag_loss_epoch = 0\n",
    "        epoch_count = 0\n",
    "        for example in range(len(logits_list)):\n",
    "            random_context_samples = random.sample(context_embeds_list, num_samples) # could use another context to see what happens\n",
    "            stacked_context_sample = torch.stack(random_context_samples, dim = 0)\n",
    "            # print(stacked_context_sample.shape)\n",
    "            optimizer.zero_grad()\n",
    "            network_output = model(stacked_context_sample.to(device), logits_list[example].to(device))\n",
    "            if token_ids_list[example]['input_ids'].shape[1] == 1:\n",
    "                print(\"ONE text id\")\n",
    "                continue\n",
    "            shifted_network_output = network_output[..., :-1, :].contiguous()\n",
    "            shifted_text_ids = token_ids_list[example]['input_ids'][..., 1:].contiguous().to(device)\n",
    "            loss = CELoss(shifted_network_output.view(-1, shifted_network_output.size(-1)), shifted_text_ids.view(-1))\n",
    "            ag_loss_epoch += loss\n",
    "            epoch_count += 1\n",
    "            total_count += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Epoch Examples: {epoch_count}\")\n",
    "        print(f\"TRAIN LOSS: {ag_loss_epoch / len(logits_list)}\")\n",
    "        # print(f\"DEV LOSS: {full_dev_loss}\")\n",
    "        print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14166441-9f91-4b3c-bbf4-8e939b93a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_gatsby_embeds[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b8c88-74d5-4804-98ad-d925dc26a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gatsby_alone_model = Model_Import.ProposedModel(R_gatsby_embeds[0].shape[0], gatsby_logits[0].shape[1], attention_dim = None)\n",
    "# optimizer = optim.Adam(gatsby_alone_model.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe802df-c984-47ad-93a6-51451b8905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_one_style(gatsby_alone_model, optimizer, R_gatsby_embeds, gatsby_logits, gatsby_token_ids, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e5337-fcb3-4708-bd0c-d47aedf88f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origins_alone_model = Model_Import.ProposedModel(R_origin_embeds[0].shape[0], origin_logits[0].shape[1], attention_dim = None)\n",
    "# origins_optimizer = optim.Adam(origins_alone_model.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d32493-90b7-4f2e-afce-6f536576eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_one_style(origins_alone_model, origins_optimizer, R_origin_embeds, origin_logits, origin_token_ids, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7280f-ba27-428a-87b9-7a318213b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_style_generate(prompt, tokenizer, SAT_model, GPT_transformer, context_to_sample, num_samples = 100, num_tokens_to_generate = 1, sen_to_generate = 10):\n",
    "  #Put models in eval mode\n",
    "    SAT_model.eval()\n",
    "    GPT_transformer.eval()\n",
    "    for sent in range(sen_to_generate):\n",
    "        random_context_samples = random.sample(context_to_sample, num_samples)\n",
    "        model_context_input =  torch.stack(random_context_samples, dim = 0)\n",
    "\n",
    "        # tokenize prompt\n",
    "        current_tokenization = tokenizer.encode(prompt, return_tensors = 'pt').to(device)\n",
    "\n",
    "        for generation in range(num_tokens_to_generate):\n",
    "            # put tokenized prompt through GPT_transformer to get GPT Logits\n",
    "            GPT_logits = GPT_transformer(current_tokenization).last_hidden_state.squeeze()\n",
    "\n",
    "            # put model_context_input and the GPT Logits into SAT model\n",
    "            adjusted_output = SAT_model(model_context_input, GPT_logits)\n",
    "\n",
    "            # Funtional softmax the SAT model output\n",
    "            SM_adjusted_output = torch.nn.functional.softmax(adjusted_output, dim = 1)\n",
    "\n",
    "            # argmax to get predicted token\n",
    "            predicted_tokens = torch.argmax(SM_adjusted_output, dim =1)\n",
    "\n",
    "            # get topk tokens\n",
    "            top_predicted_tokens = torch.topk(SM_adjusted_output[-1], 2, dim =0).indices\n",
    "\n",
    "            #dif way of getting top predicted\n",
    "            predicted_token = top_predicted_tokens[0]\n",
    "            if predicted_token == 247:\n",
    "                print(\"WEIRD TOKEN PREDICTED\")\n",
    "                predicted_token = top_predicted_tokens[1]\n",
    "\n",
    "            # print(torch.amax(SM_adjusted_output[-1]))\n",
    "\n",
    "            # print(predicted_tokens[-1].unsqueeze(0).unsqueeze(0))\n",
    "            # print(current_tokenization)\n",
    "\n",
    "            current_tokenization = torch.cat((current_tokenization, predicted_token.unsqueeze(0).unsqueeze(0)), 1)\n",
    "            # print(current_tokenization)\n",
    "\n",
    "        # decode\n",
    "        for i, beam in enumerate(current_tokenization):\n",
    "            # print(f\"{i}: {tokenizer.decode(beam)}\")\n",
    "            # print(f\"{i}: {current_tokenization}\")\n",
    "            print(f\"{i}: {tokenizer.decode(beam, skip_special_tokens=True)}\")\n",
    "    # for i, beam in enumerate(predicted_tokens):\n",
    "    #     # if i == 0:\n",
    "    #     #   continue\n",
    "    #     print(f\"{i}: {tokenizer.decode(beam, skip_special_tokens=True)} token_id: {beam}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72a990-2943-4b7b-831c-7297bdee3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"In my younger and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5211679-df96-4a91-97ec-968d498b524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_style_generate(prompt, Model_Import.tokenizer, gatsby_alone_model, Model_Import.head_transformer, R_gatsby_embeds, num_samples = 100, num_tokens_to_generate = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8b9dd-254d-4eea-a618-aca1acb85ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_style_generate(prompt, Model_Import.tokenizer, origins_alone_model, Model_Import.head_transformer, R_origin_embeds, num_samples = 100, num_tokens_to_generate = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cb70a-1014-4bc2-937d-218449c5110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_ids = Model_Import.tokenizer.encode(prompt, return_tensors = 'pt').to(device)\n",
    "# base_generation = Model_Import.head_model.generate(text_ids, max_length=20)\n",
    "# for i, beam in enumerate(base_generation):\n",
    "#       print(f\"{i}: {Model_Import.tokenizer.decode(beam, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd7c67-a151-4d6e-a816-5267ccb3561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pos_path = \"/home/ubuntu/IMDB_train/pos/\"\n",
    "neg_path = \"/home/ubuntu/IMDB_train/neg/\"\n",
    "\n",
    "pos_token_list = []\n",
    "pos_text_list = []\n",
    "neg_token_list = []\n",
    "neg_text_list = []\n",
    "\n",
    "os.chdir(pos_path)\n",
    "  \n",
    "\n",
    "for file in os.listdir():\n",
    "    with open(pos_path+file, 'r') as f:\n",
    "        pos_text = f.read()\n",
    "        # put into text list\n",
    "        pos_text_list.append(pos_text)\n",
    "        #tokenize and put into token list\n",
    "        #pos_token_list.append(base_tokenizer.encode(pos_text, return_tensors = 'pt'))\n",
    "\n",
    "os.chdir(neg_path)\n",
    "\n",
    "for file in os.listdir():\n",
    "    if not file.endswith('.txt'):\n",
    "        continue\n",
    "    with open(neg_path+file, 'r') as f:\n",
    "        neg_text = f.read()\n",
    "        # put into text list\n",
    "        neg_text_list.append(neg_text)\n",
    "        #tokenize and put into token list\n",
    "        #neg_token_list.append(base_tokenizer.encode(neg_text_list, return_tensors = 'pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439f18c-753f-423d-b954-4e46609e6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know the story - a group of plucky no-hopers enter a competition they seemingly have no chance of winning - it's a tale that has been done to death by Hollywood (Bring It On, The Karate Kid, Escape to Victory, Best of the Best etc). Now Korea gives it a go with a Taekwondo team struggling for glory  and guess what  the result is predictable but ultimately satisfying.<br /><br />The fact that this movie doesn't fall flat on its face is down to the talented young cast who really make you care about the characters, and this in turn keeps you watching to the end.<br /><br />Fans of your typical martial arts movie may be disappointed  Taekwondo does not deliver the usual flurry of moves and acrobatics seen in most Kung Fu films; the action is limited to (albeit impressive) kicking and the occasional punch. This doesn't matter though, since it is the interaction of the characters and their fight to make something of themselves which makes this movie a success.\n"
     ]
    }
   ],
   "source": [
    "print(pos_text_list[20])\n",
    "# test_text_pos = pos_text_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f5f1c-340e-42ce-b434-1b7a39675f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "# ref https://stackoverflow.com/questions/753052/strip-html-from-strings-in-python\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "# cleaned = test_text_pos.replace('<br /><br />', ' ')\n",
    "# print(cleaned)\n",
    "\n",
    "def clean_imdb(review_list):\n",
    "    for review in range(len(review_list)):\n",
    "        cleaned_review = strip_tags(review_list[review])\n",
    "        review_list[review] = cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc2007-6c39-4d7f-a266-555f5fe44b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_imdb(pos_text_list)\n",
    "clean_imdb(neg_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47469eda-abcf-4da1-b38b-3a0320a98499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend of Dragoon is one of those little-known games that people either love or hate. Some people claim it's far too similar to other games, namely the Final Fantasy series--which is understandable, since it was originally intended to be Sony's equivalent of Final Fantasy. Honestly I can't comment on the similarities beyond that, as I'm not very familiar with the FF games.I think my favorite aspect of the game is the battle system. Not only do you have the ability to change into a more powerful dragoon form, but every time you attack, you have to pay attention in order to complete the attack by pressing buttons at the correct time. Not only that, sometimes enemies will attack you back right in the middle of a sequence, which means you have to press different buttons in order to avoid taking damage. Even the use of certain attack items requires a bit of button-mashing. If you don't want to attack, you can always guard, which not only cuts any damage taken in half, but raises your hit points without the use of healing potions.The FMVs are quite well-done, about the same quality as Final Fantasy 8's. However, the graphics during game play aren't quite up to that standard. They're nice, but they could have been--and honestly, should have been--better. The translation as well leaves something to be desired. Not only does it raise interesting character relationship questions, but there are also some grammatical mistakes that simply shouldn't have been allowed to pass.Another thing I found interesting was that you lose main party characters--one dies, and the other basically becomes useless to the party and leaves. While the death of the one character is often said to have no point, it makes you realize early on that the characters, while heroes, are still just as mortal as the next person. The people who replace the lost characters simply gain all their stats, so the transition game play-wise is fairly smooth. Perhaps my one complaint about the characters is the main character's love interest, Shana. She is the epitome of the helpless female in need of rescuing, pathetic to the point of driving a player to screaming with frustration. While you can use her in your party, she is insanely weak--I don't even know what her dragoon powers are like, as I disliked her so much I never used her. The character Rose, by contrast, is probably my favorite female character in any game ever. She's no wimp, and some of her dragoon magic is extremely useful. Meru is quite strong as well, while sometimes being an annoying talkative brat.The character designers were, as most are, inclined to make the female characters appear pretty or whatever, and didn't give much thought to the actual usefulness of the outfits. Seriously, no armor and having most of your skin exposed is not helpful when fighting monsters. But I will give them props, as they do have females serving as knights in the various countries.I can't comment much on the plot, as honestly I didn't pay much attention to it beyond where I needed to go to next. I'm not sure if this says something about the plot itself, or my gaming style.All in all, it's a very enjoyable game. It has its flaws, but for me it struck just the right balance of having to think and just pressing buttons and killing monsters.\n"
     ]
    }
   ],
   "source": [
    "print(pos_text_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573afd1-40f3-47c0-a4f6-f7db6604011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG LEN: 1323.44904\n"
     ]
    }
   ],
   "source": [
    "len_sum = 0\n",
    "count = 0\n",
    "for sentence in pos_text_list:\n",
    "    len_sum += len(sentence)\n",
    "    count += 1\n",
    "print(f\"AVG LEN: {len_sum/count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92341fdc-935f-4dca-9089-2e4c8bdf17b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "empty sentence\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "R_pos_embeds = make_context_embeddings_with_mean(Roberta_model, R_tokenizer, pos_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d990aa-5ccf-45c7-9e70-828915e11f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "empty sentence\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "pos_logits, pos_token_ids = make_logits(Model_Import_6.head_transformer, Model_Import_6.tokenizer, pos_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceb836-55cb-4e1d-b12d-d670ecd8f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n",
      "12499\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_logits))\n",
    "print(len(R_pos_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5c609-4beb-4955-99bb-6de8cee197a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "R_neg_embeds = make_context_embeddings_with_mean(Roberta_model, R_tokenizer, neg_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df595b5b-2020-4e7e-8b8c-9ca9845b944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7f3de-7e32-42b6-b138-fa287c2b3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_logits, neg_token_ids = make_logits(Model_Import.head_transformer, Model_Import.tokenizer, neg_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9536131-141f-46cb-8c75-bdab74c4c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(R_pos_embeds, '/home/ubuntu/R_pos_embeds.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84550461-b1a2-4d7f-aa8b-9f38aa80d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pos_logits, '/home/ubuntu/pos_logits.pt')\n",
    "torch.save(pos_token_ids, '/home/ubuntu/pos_token_ids.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0917dc7-53c1-49e4-a122-a7c922767664",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(R_neg_embeds, '/home/ubuntu/R_neg_embeds.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574fb31-a990-40bc-bace-223a9cd268db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neg_logits, '/home/ubuntu/neg_logits.pt')\n",
    "torch.save(neg_token_ids, '/home/ubuntu/neg_token_ids.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0a3c0-2c02-46f9-b932-25a7a2b15f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([0, 1, 2, 3, 4])\n",
    "# torch.save(x, 'tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dbba3-c565-4259-bb22-89c56d405fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/IMDB_train/neg\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ef7d9-d250-4714-b2db-1392a5df495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model_Import_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909fcc9-6b5a-4cb1-82c6-f5572c0dabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model_Import_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dec7b5-aae8-480c-8ee7-5fb9d79b27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_alone_model = Model_Import_5.DeeperModel(R_pos_embeds[0].shape[0], pos_logits[0].shape[1], attention_dim = None) # 1:42 per epoch on old deep model (2 layers)\n",
    "pos_optimizer = optim.Adam(pos_alone_model.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340218e-ccc9-4aa7-b2e8-3ead60b6f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_style(pos_alone_model, pos_optimizer, R_pos_embeds, pos_logits, pos_token_ids, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416225a9-5ef3-4eb5-8413-52470ef6f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_alone_model = Model_Import.ProposedModel(R_neg_embeds[0].shape[0], neg_logits[0].shape[1], attention_dim = None) # 1:08\n",
    "neg_alone_model = Model_Import_5.DeeperModel(R_neg_embeds[0].shape[0], neg_logits[0].shape[1], attention_dim = None)\n",
    "neg_optimizer = optim.Adam(neg_alone_model.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895d0fc-ec0f-4267-85aa-bdf5645b8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_style(neg_alone_model, neg_optimizer, R_neg_embeds, neg_logits, neg_token_ids, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721fb81-dd3e-4ba5-b797-7760cc23b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model_Import_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a025b-dd3c-4c70-94a1-de68f1a8ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_alone_model = Model_Import_6.Test_skip_norm_model(R_neg_embeds[0].shape[0], neg_logits[0].shape[1], attention_dim = None)\n",
    "# neg_optimizer = optim.Adam(neg_alone_model.parameters(), lr=0.00001,  weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b93f62-97a0-4ed3-9151-849b3076851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d11521-0cda-4e0e-aa21-e78b99949ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_style_generate(prompt, Model_Import.tokenizer, pos_alone_model, Model_Import.head_transformer, R_pos_embeds, num_samples = 100, num_tokens_to_generate = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcbe89-7ea1-4d8e-a8d1-246c71be4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_style_generate(prompt, Model_Import.tokenizer, neg_alone_model, Model_Import.head_transformer, R_neg_embeds, num_samples = 100, num_tokens_to_generate = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b31fd4-a48c-49ef-843b-5f4e915cfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = Model_Import.tokenizer.encode(prompt, return_tensors = 'pt').to(device)\n",
    "base_generation = Model_Import.head_model.generate(text_ids, max_length=20)\n",
    "for i, beam in enumerate(base_generation):\n",
    "      print(f\"{i}: {Model_Import.tokenizer.decode(beam, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76346ac-44ba-4bca-8e6d-8fb3b62dc815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
